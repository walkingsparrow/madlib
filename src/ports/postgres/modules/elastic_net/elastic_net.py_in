
import plpy
from elastic_net_gaussian_igd import __elastic_net_gaussian_igd_train
from elastic_net_gaussian_fista import __elastic_net_gaussian_fista_train

# ========================================================================

def elastic_net_help(schema_madlib, family_or_optimizer, **kwargs):
    """
    Given a response family name or optimizer name, print out the related
    information.

    If a family name is given, print out the supported optimizer together
    with its default optimizer.
    
    If an optimizer name is given, print out the necessary parameters.
    """
    if (family_or_optimizer.lower() == "gaussian" or
        family_or_optimizer == "linear"):
        return """
        Supported optimizer:
        (1) Incremental gradient descent method ('igd')
        (2) Fast iterative shrinkage thesholding algorithm ('fista')

        For alpha = 0, Newton method ('newton') is also supported.    
        """

    if family_or_optimizer.lower() == "igd":
        return """
        Incremental gradient descent (IGD) method

        In order to obtain sparse coefficients, a
        modified version of IGD is actually used.

        Parameters:
        stepsize         - default 0.01
        max_iter         - default 100
        tolenrance       - default 1e-5

        Reference:
        [1] Shai Shalev-Shwartz and Ambuj Tewari, Stochastic Methods for l1    
            Regularized Loss Minimization. Proceedings of the 26th Interna-   
            tional Conference on Machine Learning, Montreal, Canada, 2009.   
        """

    if family_or_optimizer.lower() == "fista":
        return """
        Fast iterative shrinkage thesholding algorithm
        with backtracking for stepsizes

        Parameters:
        L0               - default is 0.01
        eta              - default 2
        max_iter         - default 100
        tolenrance       - default 1e-5
                
        Reference:
        [1] Beck, A. and M. Teboulle (2009), A fast iterative   
            shrinkage-thresholding algorothm for linear inverse   
            problems. SIAM J. on Imaging Sciences 2(1), 183-202.   
        """
        
    if family_or_optimizer.lower() == "newton":
        return "Newton method  "
        
    return """
    Not a supported response family or optimizer  
    """
        

# ========================================================================

# lambda is a keyword of Python, try to avoid using
# it, so use lambda_value instead
def elastic_net_train(schema_madlib, tbl_source, tbl_result, col_dep_var,
                      col_ind_var, regress_family, alpha, lambda_value,
                      standardize, grouping_col, optimizer,
                      optimizer_params, excluded, max_iter, tolerance,
                      **kwargs):
    """
    A wrapper for all variants of elastic net regularization.

    @param tbl_source        Name of data source table
    @param col_ind_var       Name of independent variable column,
                             independent variable is an array
    @param col_dep_var       Name of dependent variable column
    @param tbl_result        Name of the table to store the results,
                             will return fitting coefficients and
                             likelihood
    @param lambda_value      The regularization parameter
    @param alpha             The elastic net parameter, [0, 1]
    @param standardize       Whether to normalize the variables
    @param regress_family    Response type, 'gaussian' or 'binomial'
    @param optimizer         The optimization algorithm, for example 'igd'
    @param optimizer_params  Parameters of the above optimizer, the format
                             is '{arg = value, ...}'::varchar[]
    @param excluded Which variables are excluded when col_ind_var == "*"
    """
    # handle all special cases of col_ind_var
    (col_ind_var, outstr_array) = analyze_input_str(tbl_source, col_ind_var, col_dep_var,
                                                    excluded)
    # Special case for ridge linear regression
    if ((regress_family.lower() == "gaussian" or regress_family.lower() == "linear") and
        optimizer.lower() == "newton" and
        alpha == 0):
        plpy.execute("""select {schema_madlib}.ridge_newton_train(
                            '{tbl_source}', '{col_ind_var}', '{col_dep_var}',
                            '{tbl_result}', {lambda_value}, {standardize}
        )""".format(schema_madlib = schema_madlib,
                    tbl_source = tbl_source,
                    col_ind_var = col_ind_var,
                    col_dep_var = col_dep_var,
                    tbl_result = tbl_result,
                    lambda_value = lambda_value,
                    standardize = standardize))
        return None
    
    if ((regress_family.lower() == "gaussian" or regress_family.lower() == "linear") and
        optimizer.lower() == "igd"):
        __elastic_net_gaussian_igd_train(schema_madlib, tbl_source, col_ind_var,
                                         col_dep_var, tbl_result, lambda_value, alpha,
                                         standardize, optimizer_params, max_iter,
                                         tolerance, **kwargs)
        return None

    if ((regress_family.lower() == "gaussian" or regress_family.lower() == "linear") and
        optimizer.lower() == "fista"):
        __elastic_net_gaussian_fista_train(schema_madlib, tbl_source, col_ind_var,
                                           col_dep_var, tbl_result, lambda_value, alpha,
                                           standardize, optimizer_params, max_iter,
                                           tolerance, **kwargs)
        return None

    plpy.error("Not a supported response family or supported optimizer of the given response family!")
    return None

# ========================================================================

def analyze_input_str(tbl_source, col_ind_var, col_dep_var, excluded):
    """
    Make input strings and output strings compatible with functions

    @param tbl_source Data table
    @param col_ind_var Independent variables
    @param col_dep_var Dependent variables
    @param excluded Which variables are excluded when col_ind_var == "*"
    """
    return (col_ind_var, "")

# ========================================================================

def elastic_net_predict(schema_madlib, regress_family, coefficients,
                        intercept, ind_var, **kwargs):
    """
    Make predictions using the fitting coefficients
    """
    if regress_family.lower() == "gaussian" or regress_family.lower() == "linear":
        return __elastic_net_gaussian_predict(coefficients, intercept, ind_var)

    plpy.error("Not a supported response family!")
    return None

# ========================================================================
    
def __elastic_net_gaussian_predict(coefficients, intercept, ind_var):
    """
    Prediction for linear models
    """
    dot = intercept
    for i in range(len(coefficients)):
        dot += coefficients[i] * ind_var[i]
    return dot

    