
import plpy
from validation.cv_utils import __cv_unique_string
from utilities.control import IterationController
from convex.lasso_igd import IterationControllerNoTableDrop
from convex.ridge import __ridge_ind_var_scales
from convex.ridge import __ridge_dep_var_scale
from convex.ridge import __ridge_normalize_data
from convex.ridge import __ridge_restore_linear_coef_scales
from convex.validate_args import __is_tbl_exists
from convex.validate_args import __is_tbl_has_rows
from convex.validate_args import __is_col_exists
from convex.validate_args import __is_tbl_exists_in_schema
from convex.validate_args import __is_scalar_col_no_null
from convex.validate_args import __is_array_col_same_dimension
from convex.validate_args import __is_array_col_no_null

## ========================================================================

def __igd_params_parser(optimizer_params):
    """
    Parse IGD parameters.
    """
    allowed_params = set(["stepsize", "num_iterations", "tolerance"])
    name_value = dict()
    # default values
    name_value["stepsize"] = 0.01 
    name_value["num_iterations"] = 100 
    name_value["tolerance"] = 0.000001
    
    for s in optimizer_params:
        items = s.split("=")
        if (len(items) != 2):
            plpy.error("Optimizer parameter list has incorrect format!")
        param_name = items[0].strip()
        param_value = items[1].strip()

        if param_name not in allowed_params:
            plpy.error("{0} is not a valid parameter name for the IGD optimizer.".format(param_name))

        if param_name == "stepsize":
            name_value["stepsize"] = float(param_value)

        if param_name == "num_iterations":
            name_value["num_iterations"] = int(param_value)

        if param_name == "tolerance":
            name_value["tolerance"] = float(param_value)

    # validate the parameters
    if name_value["stepsize"] <= 0:
        plpy.error("Elastic Net error: step size must be positive!")

    if name_value["num_iterations"] <= 0:
        plpy.error("Elastic Net error: num_iterations must be positive!")

    if name_value["tolerance"] <= 0:
        plpy.error("Elastic Net error: tolerance must be positive!")

    return name_value

## ========================================================================

def __tbl_dimension_rownum(tbl_source, col_ind_var):
    """
    Measure the dimension and row number of source data table
    """
        # independent variable array length
    dimension = plpy.execute("""
                             select max(array_upper({col_ind_var},1)) as dimension
                             from {tbl_source}
                             """.format(tbl_source = tbl_source,
                                        col_ind_var = col_ind_var))[0]["dimension"]
    # total row number of data source table
    row_num = plpy.execute("""
                           select count(*) from {tbl_source}
                           """.format(tbl_source = tbl_source))[0]["count"]

    return (dimension, row_num)

## ========================================================================

def __igd_create_tbl_args(**args):
    """
    create the temporary schema and argument table used in IGD iterations
    """
    plpy.execute("select {schema_madlib}.create_schema_pg_temp()".format(**args))

    effective_lambda = args["lambda_value"] * args["row_num"]
    plpy.execute("""
                 drop table if exists pg_temp.{tbl_igd_args};
                 
                 create table pg_temp.{tbl_igd_args} (
                    dimension       integer,
                    stepsize        double precision,
                    lambda          double precision,
                    alpha           double precision,
                    total_rows      integer,
                    num_iterations  integer,
                    tolerance       double precision);
                 """.format(**args))
    plpy.execute("""
                 insert into pg_temp.{tbl_igd_args} values
                    ({dimension}, {stepsize}, {effective_lambda}, {alpha},
                     {row_num}, {num_iterations}, {tolerance})
                 """.format(effective_lambda = effective_lambda,
                            **args))

    return None
    
## ========================================================================

def __igd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var,
                         tbl_result, dimension, row_num, lambda_value, alpha,
                         normalization, optimizer_params_dict):
    """
    Construct the dict used by a series of SQL queries in IGD optimizer.
    """
    args = dict(schema_madlib = schema_madlib, tbl_source = tbl_source,
                tbl_data = tbl_source, # argument name used in normalization
                col_ind_var = col_ind_var, col_dep_var = col_dep_var,
                tbl_result = tbl_result,
                lambda_value = lambda_value, alpha = alpha,
                dimension = dimension, row_num = row_num,
                normalization = normalization)
    
    # Add the optimizer parameters
    args.update(optimizer_params_dict)

    # Table names useful when normalizing the original data
    # Note: in order to be consistent with the calling convention
    # of the normalization functions, multiple elements of the dict
    # actually have the same value. This is a price that one has to pay
    # if he wants to save typing argument names by using **args as the
    # function argument.
    tbl_ind_scales = __cv_unique_string()
    tbl_dep_scale = __cv_unique_string()
    tbl_data_scaled = __cv_unique_string()
    args.update(tbl_scale = tbl_dep_scale, tbl_dep_scale = tbl_dep_scale,
                tbl_scales = tbl_ind_scales, tbl_ind_scales = tbl_ind_scales,
                tbl_data_scaled = tbl_data_scaled)

    # Table names used in IGD iterations
    args.update(tbl_igd_state = __cv_unique_string(),
                tbl_igd_args = __cv_unique_string())

    # Table name used as the intermediate storage before scale restores
    args.update(tbl_inter_result = __cv_unique_string())
   
    return args

## ========================================================================

def __igd_cleanup_temp_tbls(**args):
    """
    Drop all temporary tables used by IGD optimizer,
    including tables used in the possible normalization
    and IGD iterations.
    """
    plpy.execute("""
                 drop table if exists {tbl_ind_scales};
                 drop table if exists {tbl_dep_scale};
                 drop table if exists {tbl_data_scaled};
                 drop table if exists pg_temp.{tbl_igd_args};
                 drop table if exists pg_temp.{tbl_igd_state};
                 """.format(**args))
    return None

## ========================================================================

def __normalize_data(**args):
    """
    Compute the scaling factors for independent and dependent
    variables, and then scale the original data.

    The output is stored in tbl_data_scaled
    """
    __ridge_ind_var_scales(**args)
    __ridge_dep_var_scale(**args)
    __ridge_normalize_data(**args)

    return None
    
## ========================================================================

def __elastic_net_gaussian_igd_train(schema_madlib, tbl_source, col_ind_var,
                                     col_dep_var, tbl_result, lambda_value, alpha,
                                     normalization, optimizer_params, **kwargs):
    (tbl_source,
     col_ind_var,
     col_dep_var,
     tbl_result,
     lambda_value,
     alpha) = __elastic_net_gaussian_igd_validate_args(tbl_source,
                                                       col_ind_var,
                                                       col_dep_var,
                                                       tbl_result,
                                                       lambda_value,
                                                       alpha)
    
    return __elastic_net_gaussian_igd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                                    col_dep_var, tbl_result, lambda_value, alpha,
                                                    normalization, optimizer_params, **kwargs)
    
## ========================================================================

def __elastic_net_gaussian_igd_validate_args(tbl_source, col_ind_var, col_dep_var,
                                             tbl_result, lambda_value, alpha):
    if not __is_tbl_exists(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " does not exist!")

    if __is_tbl_exists_in_schema(tbl_result):
        plpy.error("Elastic Net error: Output table " + tbl_result + " already exists!")

    if not __is_tbl_has_rows(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " is empty!")

    if not __is_col_exists(tbl_source, [col_ind_var, col_dep_var]):
        plpy.error("Elastic Net error: Some column does not exist!")

    if not __is_scalar_col_no_null(tbl_source, col_dep_var):
        plpy.error("Elastic Net error: Dependent variable has Null values! Please filter out Null values before using this function!")

    if not __is_array_col_same_dimension(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have unequal lengths!")

    if not __is_array_col_no_null(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have Null values! Please filter out Null values before using this function!")

    if lambda_value < 0:
        plpy.error("Elastic Net error: The regulation parameter lambda cannot be negative!")

    if alpha < 0 or alpha > 1:
        plpy.error("Elastic Net error: The elastic net control parameter alpha must be in [0,1] !")

    return (tbl_source, col_ind_var, col_dep_var, tbl_result, lambda_value, alpha)
    
## ========================================================================
    
def __elastic_net_gaussian_igd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                             col_dep_var, tbl_result, lambda_value, alpha,
                                             normalization, optimizer_params, **kwargs):
    """
    Fit linear model with elastic net regulation using IGD optimization.

    @param tbl_source        Name of data source table
    @param col_ind_var       Name of independent variable column,
                             independent variable is an array
    @param col_dep_var       Name of dependent variable column
    @param tbl_result        Name of the table to store the results,
                             will return fitting coefficients and
                             likelihood
    @param lambda_value      The regulation parameter
    @param alpha             The elastic net parameter, [0, 1]
    @param normalization     Whether to normalize the variables
    @param optimizer_params  Parameters of the above optimizer, the format
                             is '{arg = value, ...}'::varchar[]
    """
    old_msg_level = plpy.execute("""
                                 select setting from pg_settings
                                 where name='client_min_messages'
                                 """)[0]['setting']
    plpy.execute("set client_min_messages to error")

    (dimension, row_num) = __tbl_dimension_rownum(tbl_source, col_ind_var)

    # generate a full dict to ease the following string format
    # including several temporary table names
    args = __igd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var, tbl_result,
                                dimension, row_num, lambda_value, alpha, normalization,
                                __igd_params_parser(optimizer_params))

    # use normalized data or not
    if normalization:
        __normalize_data(**args)
        tbl_used = args["tbl_data_scaled"]
    else:
        tbl_used = tbl_source

    # create the temp table that passes parameter values to IGD optimizer
    __igd_create_tbl_args(**args)

    # perform the actual calculation
    iteration_run = __compute_gaussian_igd(schema_madlib, args["tbl_igd_args"],
                                           args["tbl_igd_state"], tbl_used,
                                           col_ind_var, col_dep_var, True)

    if normalization:
        use_temp = "temp"
    else:
        args["tbl_inter_result"] = tbl_result
        use_temp = ""
    plpy.execute("""
                 drop table if exists {tbl_inter_result};
                 create {use_temp} table {tbl_inter_result} (
                    coefficients      double precision[],
                    intercept         double precision,
                    log_likelihood    double precision,
                    normalization     boolean)
                 """.format(use_temp = use_temp, **args))

    plpy.execute("""
                 insert into {tbl_inter_result}
                    select
                        (result).coefficients[1:{dimension}],
                        (result).coefficients[{dimension}+1],
                        0, False
                    from (
                        select {schema_madlib}.__gaussian_igd_result(_state) as result
                        from {tbl_igd_state}
                        where _iteration = {iteration_run}
                    ) t
                 """.format(iteration_run = iteration_run, **args))

    # compute the likelihood
    plpy.execute("""
                 update {tbl_inter_result} set log_likelihood = llhd from (
                    select
                        -(loss + {lambda_value} * ((1 - {alpha}) * module_2 / 2. + {alpha} * module_1)) as llhd
                    from (
                        select
                            avg(({col_dep_var} - {schema_madlib}.gaussian_igd_predict(coefficients, intercept, {col_ind_var}))^2) / 2. as loss
                        from
                            {tbl_inter_result},
                            {tbl_used}
                        ) t1,
                        (
                            select sum(coef^2) as module_2, sum(abs(coef)) as module_1
                            from (
                                select unnest(coefficients) as coef
                                from {tbl_inter_result}
                            ) s
                        ) t2
                 ) u
                 """.format(tbl_used = tbl_used, **args))
    
    if normalization:
        __ridge_restore_linear_coef_scales(tbl_coef = args["tbl_inter_result"],
                                           col_coef = "coefficients",
                                           col_others = ["log_likelihood", "normalization"],
                                           tbl_origin_coef = tbl_result,
                                           **args)
        plpy.execute("update {tbl_result} set normalization = True".format(**args))

    # cleanup    
    __igd_cleanup_temp_tbls(**args)
    if normalization:
        plpy.execute("drop table if exists {tbl_inter_result}".format(**args))
    plpy.execute("set client_min_messages to " + old_msg_level)
    return None

## ========================================================================

def __compute_gaussian_igd(schema_madlib, tbl_args, tbl_state, tbl_source,
                           col_ind_var, col_dep_var, drop_table, **kwargs):
    """
    Driver function for elastic net with Gaussian response using IGD

    @param schema_madlib Name of the MADlib schema, properly escaped/quoted
    @param tbl_args Name of the (temporary) table containing all non-template
        arguments
    @param tbl_state Name of the (temporary) table containing the inter-iteration
        states
    @param rel_source Name of the relation containing input points
    @param col_ind_var Name of the independent variables column
    @param col_dep_var Name of the dependent variable column
    @param drop_table Boolean, whether to use IterationController (True) or
                      IterationControllerNoTableDrop (False)
    @param kwargs We allow the caller to specify additional arguments (all of
        which will be ignored though). The purpose of this is to allow the
        caller to unpack a dictionary whose element set is a superset of
        the required arguments by this function.
    
    @return The iteration number (i.e., the key) with which to look up the
        result in \c tbl_state
    """
    if drop_table:
        iterationCtrl = IterationController(
            rel_args = tbl_args,
            rel_state = tbl_state,
            stateType = "double precision[]",
            truncAfterIteration = False,
            schema_madlib = schema_madlib, # Identifiers start here
            rel_source = tbl_source,
            col_ind_var = col_ind_var,
            col_dep_var = col_dep_var)
    else:
        iterationCtrl = IterationControllerNoTableDrop(
            rel_args = tbl_args,
            rel_state = tbl_state,
            stateType = "double precision[]",
            truncAfterIteration = False,
            schema_madlib = schema_madlib, # Identifiers start here
            rel_source = tbl_source,
            col_ind_var = col_ind_var,
            col_dep_var = col_dep_var)

    with iterationCtrl as it:
        it.iteration = 0
        while True:
            # manually add the intercept term
            it.update("""
                      select
                        {schema_madlib}.__gaussian_igd_step(
                            array_append((_src.{col_ind_var})::double precision[], 1::double precision),
                            (_src.{col_dep_var})::double precision,
                            (select _state from {rel_state}
                                where _iteration = {iteration}),
                            (_args.lambda)::double precision,
                            (_args.alpha)::double precision,
                            ((_args.dimension) + 1)::integer,
                            (_args.stepsize)::double precision,
                            (_args.total_rows)::integer)
                      from {rel_source} as _src, {rel_args} as _args
                      """)

            if it.test("""
                       {iteration} > _args.num_iterations or
                       {schema_madlib}.__gaussian_igd_state_diff(
                            (select _state from {rel_state}
                                where _iteration = {iteration} - 1),
                            (select _state from {rel_state}
                                where _iteration = {iteration})) < _args.tolerance
                       """):
                break

    return iterationCtrl.iteration
    