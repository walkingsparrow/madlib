/* ----------------------------------------------------------------------- *//** 
 *
 * @file lasso.sql_in
 *
 * @brief SQL functions for LASSO
 * @date July 2012
 *
 * @sa For a brief introduction to LASSO, see the module
 *     description \ref grp_lasso.
 *
 *//* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4') --'

/**
@addtogroup grp_lasso


@about

This module implements LASSO (least absolute shrinkage and selection operator) [1].
Mathematically, this model seeks to find a weight vector \f$w\f$ (also referred as hyperplane) that, for any given training example set, minimizes:
\f[\min_{w \in R^N} \frac{1}{2}\left[\frac{1}{M} \sum_{m=1}^M (w^{t} x_m - y_m)^2 \right] + \lambda \|w\|_1,\f]
where \f$x_m \in R^N\f$ are values of independent variables, and \f$y_m \in R\f$ are values of the dependent variable, \f$m = 1,...,M\f$.

@input

The <b>training examples</b> is expected to be of the following form:
<pre>{TABLE|VIEW} <em>input_table</em> (
    ...
    <em>independentVariables</em>    DOUBLE PRECISION[],
    <em>dependentVariables</em>    DOUBLE PRECISION,
    ...
)</pre>

Null values are not expected.


@usage

- Get the vector of coefficients \f$ \boldsymbol w \f$:

<pre>SELECT madlib.lasso_igd_run(
    '<em>modelTableName</em>', '<em>sourceTableName</em>', '<em>independentVariables</em>', '<em>dependentVariables</em>' 
    [, <em>independentVariableDimension</em> [, <em>stepSize</em> [, <em>lambda</em> [, <em>totalRows</em> [, 
    <em>numberOfIterations</em>, <em>tolerance</em> ]]]]]); 
</pre>

  Output:
  <pre>      id | coefficients | loss
  -------+--------------+--------
        ...
  </pre>
  The default value of \f$ \lambda \f$ is 0.1. The model table can contain multiple fits to different data sets, and each fit has a unique id number.
- Get the prediction on a data set using the fitted model:
<pre>
SELECT madlib.lasso_igd_predict('<em>coefficients</em>', '<em>independentVariables</em>')
FROM sourceTableName, modelTableName WHERE modelTableName.id=fitId;
</pre>

- Input data normalization:\n
we offer IGD solver (optimizer) for LASSO. IGD is expected to be fastwhen the input data has a lot of examples. 
But IGD suffers slow convergence rate if the input features is not well-conditioned or a bad stepsize is given. 
Before functions are called, we suggest that the features got normalized to have mean (average) to be 0.0, and 
standard deviation to be 1.0.

- Stepsize choice:\n
Both solvers will output the loss value for the each iteration. In a simple description, a good stepsize is the 
maximal positive number that guarantees decreases of loss values iteration by iteration. Usually, users can try 
0.01 first, and then follow this rule until the loss does not change much within reasonable numbers of iterations. 
If stepsize \f$\alpha\f$ is too large (loss is increasing), then \f$\alpha / 10\f$ should be tried next; otherwise 
\f$\alpha * 10\f$. The factor \f$10\f$ can be shrinked later for a more accurate stepsize if needed.


@examp

-# Prepare an input table/view:
\code
CREATE TABLE lasso_data (
    ind_var DOUBLE PRECISION[],
    dep_var DOUBLE PRECISION
);
\endcode     
-# Populate the input table with some data, which should be well-conditioned, e.g.:
\code
mydb=# INSERT INTO lasso_data values ({1, 1}, 0.89);
mydb=# INSERT INTO lasso_data values ({0.67, -0.06}, 0.3);
...
mydb=# INSERT INTO lasso_data values ({0.15, -1.3}, -1.3);
\endcode   
-# call lasso_igd_run() to learn coefficients, e.g.:  
\code
mydb=# SELECT madlib.lasso_igd_run('lasso_model', 'lasso_data', 'ind_var', 'dep_var', 2, 0.01, 0.1, 1000, 10, 1e-6);
\endcode
-# call lasso_igd_predict() to predict results. you usually need the model id output from the learning query to locate the model, assuming 1, e.g.:  
\code
mydb=# select madlib.lasso_igd_predict(coefficients, ind_var)
mydb-# from lasso_data, lasso_model
mydb-# where lasso_model.id = 1;
\endcode


@literature

[1] LASSO method. http://en.wikipedia.org/wiki/Lasso_(statistics)#LASSO_method

[2] Regularization: Ridge Regression and the LASSO. http://www-stat.stanford.edu/~owen/courses/305/Rudyregularization.pdf

*/

CREATE TYPE MADLIB_SCHEMA.__lasso_result AS (
        coefficients    DOUBLE PRECISION[],
        loss            DOUBLE PRECISION
);

--------------------------------------------------------------------------
-- create SQL functions for IGD optimizer
--------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__lasso_igd_transition(
        state           DOUBLE PRECISION[],
        ind_var         DOUBLE PRECISION[],
        dep_var         DOUBLE PRECISION,
        previous_state  DOUBLE PRECISION[],
        dimension       INTEGER,
        stepsize        DOUBLE PRECISION,
        lambda          DOUBLE PRECISION,
        total_rows      BIGINT)
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME', 'lasso_igd_transition'
LANGUAGE C IMMUTABLE;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__lasso_igd_merge(
        state1 DOUBLE PRECISION[],
        state2 DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME', 'lasso_igd_merge'
LANGUAGE C IMMUTABLE STRICT;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__lasso_igd_final(
        state DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME', 'lasso_igd_final'
LANGUAGE C IMMUTABLE STRICT;

------------------------------------------------------------------------
/**
 * @internal
 * @brief Perform one iteration of the incremental gradient
 *        method for computing LASSO
 */
CREATE AGGREGATE MADLIB_SCHEMA.__lasso_igd_step(
        /*+ ind_var */          DOUBLE PRECISION[],
        /*+ dep_var */          DOUBLE PRECISION,
        /*+ previous_state */   DOUBLE PRECISION[],
        /*+ dimension */        INTEGER,
        /*+ stepsize */         DOUBLE PRECISION,
        /*+ lambda */           DOUBLE PRECISION,
       /*+  total_rows */       BIGINT) (
    STYPE = DOUBLE PRECISION[],
    SFUNC = MADLIB_SCHEMA.__lasso_igd_transition,
    m4_ifdef(`GREENPLUM',`prefunc = MADLIB_SCHEMA.__lasso_igd_merge,')
    FINALFUNC = MADLIB_SCHEMA.__lasso_igd_final,
    INITCOND = '{0,0,0,0,0,0,0,0}'
);

------------------------------------------------------------------------

CREATE FUNCTION MADLIB_SCHEMA.__lasso_igd_distance(
    /*+ state1 */ DOUBLE PRECISION[],
    /*+ state2 */ DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION AS
'MODULE_PATHNAME', 'internal_lasso_igd_distance'
LANGUAGE c IMMUTABLE STRICT;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__lasso_igd_result(
    /*+ state */ DOUBLE PRECISION[])
RETURNS MADLIB_SCHEMA.__lasso_result AS
'MODULE_PATHNAME', 'internal_lasso_igd_result'
LANGUAGE c IMMUTABLE STRICT;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__lasso_execute_using_igd_args(
    sql VARCHAR, INTEGER, DOUBLE PRECISION, DOUBLE PRECISION, INTEGER, 
    INTEGER, DOUBLE PRECISION)
RETURNS VOID
IMMUTABLE
CALLED ON NULL INPUT
LANGUAGE c
AS 'MODULE_PATHNAME', 'exec_sql_using';

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.__compute_lasso_igd(
    rel_args        VARCHAR,
    rel_state       VARCHAR,
    rel_source      VARCHAR,
    col_ind_var     VARCHAR,
    col_dep_var     VARCHAR)
RETURNS INTEGER
AS $$PythonFunction(convex, lasso_igd, compute_lasso_igd)$$
LANGUAGE plpythonu VOLATILE;

------------------------------------------------------------------------
/**
 * @brief LASSO using incremental gradient
 *
 * This function takes as input the table representation of a set of examples
 * in (FLOAT8[], FLOAT8) format and outputs the coefficients that minimizes
 * the ordinary least squares with a L1 regularization term.
 *
 *   @param rel_output  Name of the table that the factors will be appended to
 *   @param rel_source  Name of the table/view with the source data
 *   @param col_ind_var  Name of the column containing feature vector (independent variables)
 *   @param col_dep_var  Name of the column containing label (dependent variable)
 *   @param dimension  Number of features (independent variables)
 *   @param stepsize  Hyper-parameter that decides how aggressive that the gradient steps are
 *   @param lambda  Hyper-parameter that decides how much the L1 regularization takes effect
 *   @param total_rows  Number of rows of the input table
 *   @param num_iterations  Maximum number if iterations to perform regardless of convergence
 *   @param tolerance  Acceptable level of error in convergence.
 *   @param normalization Whether to normalize the dependent variables, the result will be given in the original scale
 * 
 */
CREATE FUNCTION MADLIB_SCHEMA.lasso_igd_train(
    tbl_source      VARCHAR,
    col_ind_var     VARCHAR,
    col_dep_var     VARCHAR,
    tbl_output      VARCHAR,
    lambda          DOUBLE PRECISION, /*+ DEFAULT 0.1 */
    normalization   BOOLEAN, /*+ DEFAULT f to save computation */
    stepsize        DOUBLE PRECISION, /*+ DEFAULT 0.01 */
    num_iterations  INTEGER, /*+ DEFAULT 10 */
    tolerance       DOUBLE PRECISION /*+ DEFAULT 0.000001 */
) RETURNS VOID AS $$
DECLARE
    iteration_run           INTEGER;
    loss                    DOUBLE PRECISION;
    old_messages            VARCHAR;
    tbl_inter               VARCHAR;
    tbl_ind_scales          VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_dep_scale           VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_data_scaled         VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_inter_result        VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_lasso_igd_args      VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_lasso_igd_state     VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    use_temp                VARCHAR;
    dep_std                 DOUBLE PRECISION;
    total_rows              INTEGER;
    dimension               INTEGER;
BEGIN
    old_messages := (SELECT setting FROM pg_settings WHERE name = 'client_min_messages');
    EXECUTE 'SET client_min_messages TO error';
    /* RAISE NOTICE 'Source table % to be used: dimension %', rel_source, dimension; */

    EXECUTE 'SELECT max(array_upper('|| col_ind_var ||', 1)) FROM '|| tbl_source INTO dimension;
    EXECUTE 'SELECT count(*) FROM '|| tbl_source INTO total_rows;
    
    -- normaliza the data
    IF normalization THEN
        PERFORM MADLIB_SCHEMA.__ridge_ind_var_scales(tbl_source, col_ind_var, total_rows, dimension, tbl_ind_scales);
        PERFORM MADLIB_SCHEMA.__ridge_dep_var_scale(tbl_source, col_dep_var, total_rows, tbl_dep_scale);
        PERFORM MADLIB_SCHEMA.__ridge_normalize_data(tbl_source, col_ind_var, dimension, col_dep_var,
                                                    tbl_ind_scales, tbl_dep_scale, tbl_data_scaled);
        tbl_inter := tbl_data_scaled;
        EXECUTE 'SELECT dep_std FROM '|| tbl_dep_scale INTO dep_std;
    ELSE
        tbl_inter := tbl_source;
        dep_std := 1;
    END IF;

    -- We first setup the argument table. Rationale: We want to avoid all data
    -- conversion between native types and Python code. Instead, we use Python
    -- as a pure driver layer.

    PERFORM MADLIB_SCHEMA.create_schema_pg_temp();
    -- Unfortunately, the EXECUTE USING syntax is only available starting
    -- PostgreSQL 8.4:
    -- http://www.postgresql.org/docs/8.4/static/plpgsql-statements.html#PLPGSQL-STATEMENTS-EXECUTING-DYN
    -- We therefore have to emulate.
    -- In order to have consistent result with R glmnet package when using normalization
    -- use lambda * row_num / dep_std instead of a simple lambda
    PERFORM MADLIB_SCHEMA.__lasso_execute_using_igd_args('
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_args ||';
        CREATE TABLE pg_temp.'|| tbl_lasso_igd_args ||' AS
        SELECT 
            $1 AS dimension, 
            $2 AS stepsize,
            $3 AS lambda,
            $4 AS total_rows,
            $5 AS num_iterations, 
            $6 AS tolerance;
        ',
        dimension, stepsize, lambda*total_rows/dep_std, total_rows, num_iterations, tolerance);

    -- Perform acutal computation.
    -- Unfortunately, Greenplum and PostgreSQL <= 8.2 do not have conversion
    -- operators from regclass to varchar/text.
    iteration_run := MADLIB_SCHEMA.__compute_lasso_igd(tbl_lasso_igd_args, tbl_lasso_igd_state,
                                                        tbl_inter, col_ind_var, col_dep_var);

    -- create result table if it does not exist
    IF normalization IS False THEN
        tbl_inter_result := tbl_output;
        use_temp := '';
    ELSE
        use_temp := 'TEMP';
    END IF;
    EXECUTE '
        DROP TABLE IF EXISTS '|| tbl_inter_result ||';
        CREATE '|| use_temp ||' TABLE '|| tbl_inter_result ||' (
            coefficients    DOUBLE PRECISION[],
            intercept       DOUBLE PRECISION,
            loss            DOUBLE PRECISION,
            normalization   BOOLEAN)';

    -- A work-around for GPDB not supporting RETURNING for INSERT
    -- We generate an id using nextval before INSERT 
    -- EXECUTE '
    -- SELECT nextval(' || quote_literal(rel_output || '_id_seq') ||'::regclass)'
    -- INTO model_id;

    -- output model
    -- Retrieve result from state table and insert it
    -- DROP TABLE IF EXISTS __lasso_igd_results_temp_storage;
    /*
    EXECUTE '
        CREATE TEMP TABLE __lasso_igd_results_temp_storage AS
        (
            SELECT MADLIB_SCHEMA.internal_lasso_igd_result(_state) AS result
            FROM _madlib_lasso_igd_state
            WHERE _iteration = ' || iteration_run || '
        );
    ';
    */
    
    EXECUTE '
        INSERT INTO ' || tbl_inter_result || '
            SELECT (result).coefficients, 0, (result).loss/'||total_rows||', False
            FROM (
                    SELECT MADLIB_SCHEMA.__lasso_igd_result(_state) AS result
                    FROM '|| tbl_lasso_igd_state ||'
                    WHERE _iteration = ' || iteration_run || '
            ) t
    ';
    
    IF normalization THEN -- restore the original scales in the result
        PERFORM MADLIB_SCHEMA.__ridge_restore_linear_coef_scales(tbl_inter_result, 'coefficients', '{loss, normalization}'::VARCHAR[],
                                                                dimension, tbl_ind_scales, tbl_dep_scale, tbl_output);
        EXECUTE 'UPDATE '|| tbl_output ||' SET normalization =True';
    END IF;

/*
    EXECUTE '
    SELECT loss
    FROM ' || rel_output || '
    WHERE id = ' || model_id
    INTO loss;
*/

    EXECUTE 'DROP TABLE IF EXISTS '|| tbl_ind_scales ||';
        DROP TABLE IF EXISTS '|| tbl_dep_scale ||';
        DROP TABLE IF EXISTS '|| tbl_data_scaled ||';
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_state ||';
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_args;

    IF normalization THEN
        EXECUTE 'DROP TABLE IF EXISTS '|| tbl_inter_result;
    END IF;

    EXECUTE 'SET client_min_messages TO ' || old_messages;

/*
    -- return description
    RAISE NOTICE '
        Finished LASSO using incremental gradient 
            * table : % (%, %)
        Results:
            * loss = %
        Output:
            * view : SELECT * FROM % WHERE id = %',
        rel_source, col_ind_var, col_dep_var, loss, rel_output, model_id;
*/

END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.lasso_igd_train(
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_output          VARCHAR,
    lambda              DOUBLE PRECISION,
    normalization       BOOLEAN,
    stepsize            DOUBLE PRECISION,
    num_iterations      INTEGER
) RETURNS VOID AS $$
BEGIN
    PERFORM MADLIB_SCHEMA.lasso_igd_train($1, $2, $3, $4, $5, $6, $7, $8, 0.000001);
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.lasso_igd_train(
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_output          VARCHAR,
    lambda              DOUBLE PRECISION,
    normalization       BOOLEAN,
    stepsize            DOUBLE PRECISION
) RETURNS VOID AS $$
BEGIN
    PERFORM MADLIB_SCHEMA.lasso_igd_train($1, $2, $3, $4, $5, $6, $7, 100);
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.lasso_igd_train(
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_output          VARCHAR,
    lambda              DOUBLE PRECISION,
    normalization       BOOLEAN
) RETURNS VOID AS $$
BEGIN
    PERFORM MADLIB_SCHEMA.lasso_igd_train($1, $2, $3, $4, $5, $6, 0.01);
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
CREATE FUNCTION MADLIB_SCHEMA.lasso_igd_train(
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_output          VARCHAR,
    lambda              DOUBLE PRECISION
) RETURNS VOID AS $$
BEGIN
    -- set stepsize as default 0.01
    PERFORM MADLIB_SCHEMA.lasso_igd_train($1, $2, $3, $4, $5, False);
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
/**
 * @brief Prediction (real value) using learned coefficients for a given example.
 *
 * @param coefficients  Weight vector (hyperplane, classifier)
 * @param ind_var  Features (independent variables)
 *
 */
CREATE FUNCTION MADLIB_SCHEMA.__lasso_linear_igd_predict(
        coefficients    DOUBLE PRECISION[],
        ind_var         DOUBLE PRECISION[])
RETURNS DOUBLE PRECISION
AS 'MODULE_PATHNAME', 'lasso_igd_predict'
LANGUAGE C IMMUTABLE STRICT;

-- predict multiple data points given in a table
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.lasso_linear_igd_predict(
    tbl_model       VARCHAR,
    tbl_new_data    VARCHAR,
    ind_var         VARCHAR,
    id_var          VARCHAR,    -- ID column
    tbl_prediction  VARCHAR
) RETURNS VOID AS $$
DECLARE
    old_messages    VARCHAR;
    normalization   BOOLEAN;
BEGIN
    old_messages := (SELECT setting FROM pg_settings WHERE name = 'client_min_messages');
    EXECUTE 'SET client_min_messages TO warning';

    EXECUTE '
        DROP TABLE IF EXISTS '|| tbl_prediction ||';
        CREATE TABLE '|| tbl_prediction ||' AS
            SELECT
                '|| tbl_new_data ||'.'|| id_var ||' AS id,
                MADLIB_SCHEMA.__lasso_linear_igd_predict(
                    coefficients,
                    '|| tbl_new_data ||'.'|| ind_var ||') AS prediction
                FROM
                    '|| tbl_new_data ||',
                    '|| tbl_model;

    EXECUTE 'SELECT normalization FROM '|| tbl_model INTO normalization;
    IF normalization THEN
        EXECUTE 'UPDATE '|| tbl_prediction ||' SET prediction = prediction + intercept FROM '|| tbl_model;
    END IF;
                    
    EXECUTE 'SET client_min_messages TO ' || old_messages;
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
/*
    cross validation for lasso only
*/
/**
 * @brief Run cross validation for ridge regression
 *
 * This function does not have the limitation on the number of lambda values
 */
 
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.lasso_igd_cv(
    tbl_source          VARCHAR,
    data_id             VARCHAR,
    id_is_random        BOOLEAN,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    lambda_values       DOUBLE PRECISION[],
    normalization       BOOLEAN,
    stepsize            DOUBLE PRECISION, /*+ DEFAULT 0.01 */
    num_iterations      INTEGER, /*+ DEFAULT 10 */
    tolerance           DOUBLE PRECISION, /*+ DEFAULT 0.000001 */
    fold_num            INTEGER,
    upto_fold           INTEGER,
    validation_result   VARCHAR
) RETURNS VOID AS $$
DECLARE
    oldClientMinMessages    VARCHAR;
    tbl_used                VARCHAR; -- table name that will be used
    tbl_all_data            VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- if need to copy the data, this is the copied table name
    tbl_inter               VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- table name before normalization
    tbl_train               VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- table name for training
    tbl_valid               VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- table name for validation
    col_random_id           VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- column name for random id
    tbl_random_id           VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- table for random ID mapping
    tbl_coef                VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_accum_error         VARCHAR := MADLIB_SCHEMA.__cv_unique_string();  -- accumulate the error information
    row_num                 INTEGER;
    row_num_train           INTEGER;
    data_cols               VARCHAR[];
    error                   DOUBLE PRECISION;
    lambda                  DOUBLE PRECISION;
    dimension               INTEGER;
    accum_count             INTEGER;
    coef_count              INTEGER;
    tbl_ind_scales          VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_dep_scale           VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    dep_std                 DOUBLE PRECISION := 1;
    num_lambda_values       INTEGER := array_upper(lambda_values, 1);
    tbl_lasso_igd_args      VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    tbl_lasso_igd_state     VARCHAR := MADLIB_SCHEMA.__cv_unique_string();
    iteration_run           INTEGER;
BEGIN
    oldClientMinMessages :=  (SELECT setting FROM pg_settings WHERE name = 'client_min_messages');
    EXECUTE 'SET client_min_messages TO error';

    data_cols := array[col_ind_var, col_dep_var];
    IF data_id IS NULL THEN -- unique ID column is not given, has to copy the data and create the ID
        PERFORM MADLIB_SCHEMA.__cv_copy_data_with_id(tbl_source, data_cols, tbl_all_data, col_random_id);
        tbl_used := tbl_all_data;
    ELSIF id_is_random THEN -- unique ID column is given and is random
        tbl_used := tbl_source; -- nothing needs to be done to the original data table
    ELSE -- the provided unique ID is not random, create a table mapping the given ID to a random ID
        PERFORM MADLIB_SCHEMA.__cv_generate_random_id(tbl_source, data_id, tbl_random_id, col_random_id, data_id);
        tbl_used := tbl_source;
    END IF;

    -- k-fold cross-validation
    EXECUTE 'SELECT count(*) FROM '|| tbl_source INTO row_num;
    EXECUTE 'SELECT max(array_upper('|| col_ind_var ||', 1)) FROM '|| tbl_source INTO dimension;
    
    IF fold_num <= 1 THEN
        RAISE EXCEPTION 'Cross validation total fold number should be larger than 1!';
    END IF;
    
    IF upto_fold < 1 OR upto_fold > fold_num THEN
        RAISE EXCEPTION 'Cannot run with cross validation fold smalled than 1 or larger than total fold number!';
    END IF;

    EXECUTE '
        DROP TABLE IF EXISTS '|| tbl_coef ||';
        CREATE TEMP TABLE '|| tbl_coef ||' (id integer, coef double precision[], intercept double precision)
    ';

    PERFORM MADLIB_SCHEMA.__lasso_execute_using_igd_args('
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_args ||';
        CREATE TABLE pg_temp.'|| tbl_lasso_igd_args ||' AS
            SELECT 
                $1 AS dimension, 
                $2 AS stepsize,
                $3 AS lambda,
                $4 AS total_rows,
                $5 AS num_iterations, 
                $6 AS tolerance;',
        dimension, stepsize, 0, 0, num_iterations, tolerance);
    
    accum_count := 0;
    coef_count := 0;
    PERFORM MADLIB_SCHEMA.create_schema_pg_temp();
    FOR k IN 1..upto_fold LOOP
        --raise warning '% ***********', k;
        -- split data into train and validation parts
        IF (data_id IS NULL) OR (data_id IS NOT NULL AND id_is_random) THEN
            PERFORM MADLIB_SCHEMA.__cv_split_data(tbl_used, col_random_id, row_num, tbl_inter, tbl_valid, fold_num, k);
        ELSE
            PERFORM MADLIB_SCHEMA.__cv_split_data(tbl_used, tbl_random_id, col_random_id, data_id,
                                                row_num, tbl_inter, tbl_valid, fold_num, k);
        END IF;

        EXECUTE 'SELECT count(*) FROM '|| tbl_inter INTO row_num_train;

        -- normalization the training table
        IF normalization THEN
            PERFORM MADLIB_SCHEMA.__ridge_ind_var_scales(tbl_inter, col_ind_var, row_num_train, dimension, tbl_ind_scales);
            PERFORM MADLIB_SCHEMA.__ridge_dep_var_scale(tbl_inter, col_dep_var, row_num_train, tbl_dep_scale);
            PERFORM MADLIB_SCHEMA.__ridge_normalize_data(tbl_inter, col_ind_var, dimension, col_dep_var,
                                                        tbl_ind_scales, tbl_dep_scale, tbl_train);
            EXECUTE 'SELECT dep_std FROM '|| tbl_dep_scale INTO dep_std;
        ELSE
            tbl_train := tbl_inter;
        END IF;

        EXECUTE 'UPDATE pg_temp.'|| tbl_lasso_igd_args ||' SET total_rows = '|| row_num_train;
 
        FOR k1 IN 1..num_lambda_values LOOP
            lambda := lambda_values[k1];
            --raise warning '******* %', k1;

            EXECUTE 'UPDATE pg_temp.'|| tbl_lasso_igd_args ||' SET lambda = '|| lambda * row_num_train / dep_std;
            
            iteration_run := MADLIB_SCHEMA.__compute_lasso_igd(tbl_lasso_igd_args, tbl_lasso_igd_state,
                                                            tbl_train, col_ind_var, col_dep_var);

            coef_count := coef_count + 1;
            EXECUTE '
                INSERT INTO ' || tbl_coef || '
                    SELECT
                        '|| coef_count ||',
                        (result).coefficients,
                        0
                    FROM (
                        SELECT MADLIB_SCHEMA.__lasso_igd_result(_state) AS result
                        FROM '|| tbl_lasso_igd_state ||'
                        WHERE _iteration = ' || iteration_run || '
                    ) t
            ';

            IF normalization THEN
                coef_count := coef_count + 1;
                EXECUTE '
                    INSERT INTO '|| tbl_coef ||'
                    SELECT
                        '|| coef_count ||',
                        coefficients,
                        intercept + dep_avg
                    FROM (
                        SELECT
                            array_agg(val ORDER BY attr) AS coefficients,
                            sum(intercept_tmp) AS intercept,
                            max(dep_avg) AS dep_avg
                        FROM (
                            SELECT
                                subq2.attr,
                                (
                                    CASE WHEN std = 0 THEN
                                        0.
                                    ELSE
                                        coef * dep_std / std
                                    END
                                ) AS val,
                                (
                                    CASE WHEN std = 0 THEN
                                        0.
                                    ELSE
                                        - coef * dep_std * mean / std
                                    END
                                ) AS intercept_tmp,
                                dep_avg
                            FROM
                                '|| tbl_ind_scales ||',
                                '|| tbl_dep_scale ||',
                                (
                                    SELECT
                                        generate_series(1, '|| dimension::VARCHAR ||') AS attr,
                                        unnest(coef) AS coef
                                    FROM '|| tbl_coef ||'
                                    WHERE id = '|| coef_count - 1 ||'
                                ) AS subq2
                            WHERE '|| tbl_ind_scales ||'.attr = subq2.attr
                        ) AS subq3
                    ) AS subq1                
                ';            
            END IF;
                    
            EXECUTE '
                SELECT
                    avg((real_value - pred)^2)
                FROM (
                    SELECT
                        MADLIB_SCHEMA.__lasso_linear_igd_predict(coef, '|| tbl_valid ||'.'|| col_ind_var ||') + intercept AS pred,
                        '|| tbl_valid ||'.'|| col_dep_var ||' AS real_value
                    FROM '|| tbl_valid ||', '|| tbl_coef ||'
                    WHERE '|| tbl_coef ||'.id = '|| coef_count ||'
                    ) t
                ' INTO error;
            
            -- accumulate the measured error result
            accum_count := accum_count + 1;
            IF accum_count = 1 THEN
                EXECUTE '
                    CREATE TEMP TABLE '|| tbl_accum_error ||' (lambda DOUBLE PRECISION, mean_squared_error DOUBLE PRECISION)';
                EXECUTE '
                    INSERT INTO '|| tbl_accum_error ||' VALUES ('|| lambda ||', '|| error ||')';
            ELSE
                EXECUTE '
                    INSERT INTO '|| tbl_accum_error ||' VALUES ('|| lambda ||', '|| error ||')';
            END IF;
            
        END LOOP;
    END LOOP;

    PERFORM MADLIB_SCHEMA.__cv_summarize_result(tbl_accum_error, validation_result, 'lambda');

    EXECUTE '
        DROP TABLE IF EXISTS '|| tbl_all_data ||';
        DROP TABLE IF EXISTS '|| tbl_train ||';
        DROP TABLE IF EXISTS '|| tbl_inter ||';
        DROP TABLE IF EXISTS '|| tbl_valid ||';
        DROP TABLE IF EXISTS '|| tbl_random_id ||';
        DROP TABLE IF EXISTS '|| tbl_coef ||';
        DROP TABLE IF EXISTS '|| tbl_ind_scales ||';
        DROP TABLE IF EXISTS '|| tbl_dep_scale ||';
        DROP TABLE IF EXISTS '|| tbl_accum_error ||';
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_args ||';
        DROP TABLE IF EXISTS pg_temp.'|| tbl_lasso_igd_state;

    EXECUTE 'SET client_min_messages TO ' || oldClientMinMessages;
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------
------------------------------------------------------------------------
------------------------------------------------------------------------

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__lasso_cv_args(
    args                VARCHAR[],
    param_to_try        VARCHAR,
    param_values        DOUBLE PRECISION[],
    data_id             VARCHAR,
    id_is_random        BOOLEAN,
    validation_result   VARCHAR,
    fold_num            INTEGER
) RETURNS VARCHAR AS $$
    allowed_args = set(["tbl_source", "col_ind_var", "col_dep_var", "tbl_output", "lambda", "normalization",
                        "stepsize", "num_iterations", "tolerance"])

    name_value = dict()
    name_value["tbl_source"] = None
    name_value["col_ind_var"] = None
    name_value["col_dep_var"] = None
    name_value["lambda"] = None
    name_value["normalization"] = None
    name_value["stepsize"] = None
    name_value["num_iterations"] = None
    name_value["tolerance"] = None
    name_value["validation_result"] = "'" + validation_result + "'"
    name_value["fold_num"] = fold_num
    if data_id is None:
        name_value["data_id"] = "Null::varchar"
    else:
        name_value["data_id"] = "'" + data_id + "'"
    if id_is_random:
        name_value["id_is_random"] = "True"
    else:
        name_value["id_is_random"] = "False"
        
    if param_to_try != "lambda":
        plpy.error("Only lambda can be used to cross-validation in Ridge regression! {0} is not allowed.".format(param_to_try))
    vals = "'{" #'
    for i in range(len(param_values)):
        vals += str(param_values[i])
        if i != len(param_values) - 1:
            vals += ", "
    vals += "}'" #'
    name_value["param_values"] = vals
 
    for s in args[0]:
        items = s.split("=")
        if (len(items) != 2):
            plpy.error("Argument list syntax error!")
        arg_name = items[0].strip()
        arg_value = items[1].strip()

        if arg_name not in allowed_args:
            plpy.error("{0} is not a valid argument name for module Ridge.".format(arg_name))

        if arg_name == "tbl_source":
            name_value["tbl_source"] = "'" + arg_value + "'"
            continue

        if arg_name == "col_ind_var":
            name_value["col_ind_var"] = "'" + arg_value + "'"
            continue

        if arg_name == "col_dep_var":
            name_value["col_dep_var"] = "'" + arg_value + "'"
            continue

        if arg_name == "lambda":
            name_value["lambda"] = arg_value
            continue

        if arg_name == "normalization":
            name_value["normalization"] = arg_value
            continue

        if arg_name == "stepsize":
            name_value["stepsize"] = arg_value
            continue

        if arg_name == "num_iterations":
            name_value["num_iterations"] = arg_value
            continue

        if arg_name == "tolerance":
            name_value["tolerance"] = arg_value
            continue
    
    if name_value["normalization"] is None:
        name_value["normalization"] = "False"

    if name_value["stepsize"] is None:
        name_value["stepsize"] = 0.01

    if name_value["num_iterations"] is None:
        name_value["num_iterations"] = 100

    if name_value["tolerance"] is None:
        name_value["tolerance"] = 0.000001

    if name_value["tbl_source"] is None or name_value["col_ind_var"] is None or name_value["col_dep_var"] is None:
        plpy.error("tbl_source, col_ind_var and col_dep_var must be provided!")
    
    arg_string = """
                    {tbl_source},
                    {data_id},
                    {id_is_random},
                    {col_ind_var},
                    {col_dep_var},
                    {param_values},
                    {normalization},
                    {stepsize},
                    {num_iterations},
                    {tolerance},
                    {fold_num},
                    {fold_num},
                    {validation_result}
                """.format(**name_value)

    return arg_string
$$ LANGUAGE plpythonu;
