
import plpy
import math
from validation.cv_utils import __cv_unique_string
from utilities.control import IterationController
from convex.lasso_igd import IterationControllerNoTableDrop
from convex.ridge import __ridge_ind_var_scales
from convex.ridge import __ridge_dep_var_scale
from convex.ridge import __ridge_normalize_data
from convex.ridge import __ridge_restore_linear_coef_scales
from convex.validate_args import __is_tbl_exists
from convex.validate_args import __is_tbl_has_rows
from convex.validate_args import __is_col_exists
from convex.validate_args import __is_tbl_exists_in_schema
from convex.validate_args import __is_scalar_col_no_null
from convex.validate_args import __is_array_col_same_dimension
from convex.validate_args import __is_array_col_no_null
from convex.elastic_net_gaussian_igd import __tbl_dimension_rownum
from convex.elastic_net_gaussian_igd import __normalize_data
from convex.lasso_igd import IterationControllerNoTableDrop

## ========================================================================

def __bcd_params_parser(optimizer_params):
    """
    Parse BCD parameters.
    """
    allowed_params = set(["num_steps", "num_iterations", "tolerance"])
    name_value = dict()
    # default values
    name_value["num_steps"] = 15
    name_value["num_iterations"] = 100 
    name_value["tolerance"] = 0.000001
    
    for s in optimizer_params:
        items = s.split("=")
        if (len(items) != 2):
            plpy.error("Optimizer parameter list has incorrect format!")
        param_name = items[0].strip()
        param_value = items[1].strip()

        if param_name not in allowed_params:
            plpy.error("{0} is not a valid parameter name for the BCD optimizer.".format(param_name))

        if param_name == "num_steps":
            name_value["num_steps"] = int(param_value)
            
        if param_name == "num_iterations":
            name_value["num_iterations"] = int(param_value)

        if param_name == "tolerance":
            name_value["tolerance"] = float(param_value)
            
    # validate the parameters
    if name_value["num_steps"] <= 0:
        plpy.error("Elastic Net error: num_steps cannot be negative!")
            
    if name_value["num_iterations"] <= 0:
        plpy.error("Elastic Net error: num_iterations must be positive!")

    if name_value["tolerance"] <= 0:
        plpy.error("Elastic Net error: tolerance must be positive!")

    return name_value

## ========================================================================

def __bcd_create_tbl_args(**args):
    """
    create the temporary schema and argument table used in BCD iterations
    """
    if args["normalization"]:
        mean = [0] * args["dimension"]
        mean_y = 0
        sq = [1] * args["dimension"]
    else:
        tmp = plpy.execute("""
                           select array_agg(mean order by attr) as mean,
                                array_agg(sq order by attr) as sq
                           from (
                                select attr, avg(val) as mean, avg(val^2) as sq
                                from (
                                    select generate_series(1,{dimension}) as attr,
                                            unnest({col_ind_var}) as val
                                    from {tbl_source}
                                ) t
                                group by attr
                            ) s
                           """.format(**args))[0]
        mean = tmp["mean"]
        sq = tmp["sq"]
        mean_y = plpy.execute("""
                              select avg({col_dep_var}) as avg from {tbl_source}
                              """.format(**args))[0]["avg"]
        
    avg = "array["
    sqstr = "array["
    for i in range(args["dimension"]):
        avg += str(mean[i]) + ","
        sqstr += str(sq[i])
        if i != args["dimension"] - 1:
            sqstr += ","
    avg += str(mean_y) + "]" # averages of independent and dependent variables, length is dimension + 1
    sqstr += "]" # averages of square of independent variables, length is dimension
    
    # plpy.execute("select {schema_madlib}.create_schema_pg_temp()".format(**args))

    effective_lambda = args["lambda_value"] * args["row_num"]
    plpy.execute("""
                 drop table if exists {tbl_bcd_args};
                 
                 create temp table {tbl_bcd_args} (
                    dimension       integer,
                    means           double precision[],
                    sq              double precision[],
                    lambda          double precision,
                    alpha           double precision,
                    total_rows      integer,
                    num_iterations  integer,
                    tolerance       double precision);
                 """.format(**args))
    plpy.execute("""
                 insert into {tbl_bcd_args} values
                    ({dimension}, {avg}, {sqstr}, {effective_lambda}, {alpha},
                     {row_num}, {num_iterations}, 0.01)
                 """.format(effective_lambda = effective_lambda, avg = avg,
                            sqstr = sqstr,
                            **args))

    return None
    
## ========================================================================

def __bcd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var,
                         tbl_result, dimension, row_num, lambda_value, alpha,
                         normalization, optimizer_params_dict):
    """
    Construct the dict used by a series of SQL queries in BCD optimizer.
    """
    args = dict(schema_madlib = schema_madlib, tbl_source = tbl_source,
                tbl_data = tbl_source, # argument name used in normalization
                col_ind_var = col_ind_var, col_dep_var = col_dep_var,
                tbl_result = tbl_result,
                lambda_value = lambda_value, alpha = alpha,
                dimension = dimension, row_num = row_num,
                normalization = normalization)
    
    # Add the optimizer parameters
    args.update(optimizer_params_dict)

    # Table names useful when normalizing the original data
    # Note: in order to be consistent with the calling convention
    # of the normalization functions, multiple elements of the dict
    # actually have the same value. This is a price that one has to pay
    # if he wants to save typing argument names by using **args as the
    # function argument.
    tbl_ind_scales = __cv_unique_string()
    tbl_dep_scale = __cv_unique_string()
    tbl_data_scaled = __cv_unique_string()
    args.update(tbl_scale = tbl_dep_scale, tbl_dep_scale = tbl_dep_scale,
                tbl_scales = tbl_ind_scales, tbl_ind_scales = tbl_ind_scales,
                tbl_data_scaled = tbl_data_scaled)

    # Table names used in BCD iterations
    args.update(tbl_bcd_state = __cv_unique_string(),
                tbl_bcd_args = __cv_unique_string())

    # Table name used as the intermediate storage before scale restores
    args.update(tbl_inter_result = __cv_unique_string())
   
    return args

## ========================================================================

def __bcd_cleanup_temp_tbls(**args):
    """
    Drop all temporary tables used by BCD optimizer,
    including tables used in the possible normalization
    and BCD iterations.
    """
    plpy.execute("""
                 drop table if exists {tbl_ind_scales};
                 drop table if exists {tbl_dep_scale};
                 drop table if exists {tbl_data_scaled};
                 
                 drop table if exists pg_temp.{tbl_bcd_state};
                 """.format(**args))
    # drop table if exists pg_temp.{tbl_bcd_args};
    return None

## ========================================================================

def __elastic_net_gaussian_bcd_train(schema_madlib, tbl_source, col_ind_var,
                                     col_dep_var, tbl_result, lambda_value, alpha,
                                     normalization, optimizer_params, **kwargs):
    (tbl_source,
     col_ind_var,
     col_dep_var,
     tbl_result,
     lambda_value,
     alpha) = __elastic_net_gaussian_bcd_validate_args(tbl_source,
                                                       col_ind_var,
                                                       col_dep_var,
                                                       tbl_result,
                                                       lambda_value,
                                                       alpha,
                                                       normalization)
    
    return __elastic_net_gaussian_bcd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                                    col_dep_var, tbl_result, lambda_value, alpha,
                                                    normalization, optimizer_params, **kwargs)
    
## ========================================================================

def __elastic_net_gaussian_bcd_validate_args(tbl_source, col_ind_var, col_dep_var,
                                             tbl_result, lambda_value, alpha,
                                             normalization):
    if (tbl_source is None or col_ind_var is None or col_dep_var is None
        or tbl_result is None or lambda_value is None or alpha is None
        or normalization is None):
        plpy.error("Elastic Net error: You have unsupported NULL value(s) in the arguments!")
    
    if not __is_tbl_exists(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " does not exist!")

    if __is_tbl_exists_in_schema(tbl_result):
        plpy.error("Elastic Net error: Output table " + tbl_result + " already exists!")

    if not __is_tbl_has_rows(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " is empty!")

    if not __is_col_exists(tbl_source, [col_ind_var, col_dep_var]):
        plpy.error("Elastic Net error: Some column does not exist!")

    if not __is_scalar_col_no_null(tbl_source, col_dep_var):
        plpy.error("Elastic Net error: Dependent variable has Null values! Please filter out Null values before using this function!")

    if not __is_array_col_same_dimension(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have unequal lengths!")

    if not __is_array_col_no_null(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have Null values! Please filter out Null values before using this function!")

    if lambda_value < 0:
        plpy.error("Elastic Net error: The regularization parameter lambda cannot be negative!")

    if alpha < 0 or alpha > 1:
        plpy.error("Elastic Net error: The elastic net control parameter alpha must be in [0,1] !")

    return (tbl_source, col_ind_var, col_dep_var, tbl_result, lambda_value, alpha)

## ========================================================================
    
def __elastic_net_gaussian_bcd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                             col_dep_var, tbl_result, lambda_value, alpha,
                                             normalization, optimizer_params, **kwargs):
    """
    Fit linear model with elastic net regularization using BCD optimization.

    @param tbl_source        Name of data source table
    @param col_ind_var       Name of independent variable column,
                             independent variable is an array
    @param col_dep_var       Name of dependent variable column
    @param tbl_result        Name of the table to store the results,
                             will return fitting coefficients and
                             likelihood
    @param lambda_value      The regularization parameter
    @param alpha             The elastic net parameter, [0, 1]
    @param normalization     Whether to normalize the variables
    @param optimizer_params  Parameters of the above optimizer, the format
                             is '{arg = value, ...}'::varchar[]
    """
    old_msg_level = plpy.execute("""
                                 select setting from pg_settings
                                 where name='client_min_messages'
                                 """)[0]['setting']
    plpy.execute("set client_min_messages to warning")

    (dimension, row_num) = __tbl_dimension_rownum(tbl_source, col_ind_var)

    # generate a full dict to ease the following string format
    # including several temporary table names
    args = __bcd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var, tbl_result,
                                dimension, row_num, lambda_value, alpha, normalization,
                                __bcd_params_parser(optimizer_params))

    # use normalized data or not
    if normalization:
        __normalize_data(**args)
        tbl_used = args["tbl_data_scaled"]
    else:
        tbl_used = tbl_source

    # create the temp table that passes parameter values to BCD optimizer
    __bcd_create_tbl_args(**args)

    # compute lambda sequence
    lambda_seq = __bcd_lambda_sequence(tbl_used, col_ind_var, col_dep_var, dimension,
                                       row_num, lambda_value, alpha, args["num_steps"])
    
    # perform the actual calculation
    iteration_run = 0
    for i in range(len(lambda_seq)):
        lv = lambda_seq[i] * row_num
        plpy.execute("""
                     update {tbl_bcd_args} set lambda = {lv}
                     """.format(lv = lv, **args))
        if i == len(lambda_seq) - 1:
            plpy.execute("""
                         update {tbl_bcd_args} set tolerance = {tolerance}
                         """.format(**args))
        iteration_run = __compute_gaussian_bcd(schema_madlib, args["tbl_bcd_args"],
                                               args["tbl_bcd_state"], tbl_used,
                                               col_ind_var, col_dep_var, iteration_run)
        if iteration_run >= args["num_iterations"]:
            break
        # plpy.warning("Current: " + str(iteration_run) + " " + str(lv))
     
    if normalization:
        use_temp = "temp"
    else:
        args["tbl_inter_result"] = tbl_result
        use_temp = ""
    plpy.execute("""
                 drop table if exists {tbl_inter_result};
                 create {use_temp} table {tbl_inter_result} (
                    coefficients      double precision[],
                    intercept         double precision,
                    log_likelihood    double precision,
                    normalization     boolean,
                    iteration_run        integer)
                 """.format(use_temp = use_temp, **args))

    plpy.execute("""
                 insert into {tbl_inter_result}
                    select
                        (result).coefficients[1:{dimension}],
                        (result).coefficients[{dimension}+1],
                        -(result).likelihood / {row_num},
                        False, {iteration_run}
                    from (
                        select {schema_madlib}.__gaussian_bcd_result(_state) as result
                        from {tbl_bcd_state}
                        where _iteration = {iteration_run}
                    ) t
                 """.format(iteration_run = iteration_run, **args))

    # # compute the likelihood
    plpy.execute("""
                 update {tbl_inter_result} set log_likelihood = llhd from (
                    select
                        -(loss + {lambda_value} * ((1 - {alpha}) * module_2 / 2. + {alpha} * module_1)) as llhd
                    from (
                        select
                            avg(({col_dep_var} - {schema_madlib}.elastic_net_predict('gaussian', coefficients, intercept, {col_ind_var}))^2) / 2. as loss
                        from
                            {tbl_inter_result},
                            {tbl_used}
                        ) t1,
                        (
                            select sum(coef^2) as module_2, sum(abs(coef)) as module_1
                            from (
                                select unnest(coefficients) as coef
                                from {tbl_inter_result}
                            ) s
                        ) t2
                 ) u
                 """.format(tbl_used = tbl_used, **args))
    
    if normalization:
        __ridge_restore_linear_coef_scales(tbl_coef = args["tbl_inter_result"],
                                           col_coef = "coefficients",
                                           col_others = ["log_likelihood", "normalization", "iteration_run"],
                                           tbl_origin_coef = tbl_result,
                                           **args)
        plpy.execute("update {tbl_result} set normalization = True".format(**args))

    # cleanup    
    __bcd_cleanup_temp_tbls(**args)
    if normalization:
        plpy.execute("drop table if exists {tbl_inter_result}".format(**args))
    plpy.execute("set client_min_messages to " + old_msg_level)
    return None

## ========================================================================

def __bcd_lambda_sequence(tbl_used, col_ind_var, col_dep_var,
                          dimension, row_num, lambda_value, alpha,
                          num_steps):
    """
    Compute lambda sequence
    """
    if num_steps == 1:
        return [lambda_value]
    
    mean_y = plpy.execute("select avg({col_dep_var}) from {tbl_used}".format(
        col_dep_var = col_dep_var, tbl_used = tbl_used))[0]["avg"]
    xy = [0] * dimension
    for i in range(1,dimension+1):
        xy[i-1] = plpy.execute("""
                             select abs(sum({col_ind_var}[{i}] * ({col_dep_var} - {mean_y})))
                             from {tbl_used}
                             """.format(col_ind_var = col_ind_var,
                                        col_dep_var = col_dep_var,
                                        mean_y = mean_y,
                                        tbl_used = tbl_used, i = i))[0]["abs"]
    largest = max(xy) / float(row_num * alpha)
    if lambda_value == 0.:
        smallest = 0.001 * largest
    else:
        smallest = lambda_value
    step = math.log(largest / smallest) / (float(num_steps) - 1)
    seq = range(num_steps)
    seq.reverse()
    for i in range(num_steps):
        seq[i] = math.exp(seq[i] * step + math.log(smallest))
    if lambda_value == 0:
        seq.append(0)

    return seq
    
## ========================================================================

def __compute_gaussian_bcd(schema_madlib, tbl_args, tbl_state, tbl_source,
                           col_ind_var, col_dep_var, start_iter):
    """
    Driver function for elastic net with Gaussian response using BCD

    @param schema_madlib Name of the MADlib schema, properly escaped/quoted
    @param tbl_args Name of the (temporary) table containing all non-template
        arguments
    @param tbl_state Name of the (temporary) table containing the inter-iteration
        states
    @param rel_source Name of the relation containing input points
    @param col_ind_var Name of the independent variables column
    @param col_dep_var Name of the dependent variable column
    @param drop_table Boolean, whether to use IterationController (True) or
                      IterationControllerNoTableDrop (False)
    @param kwargs We allow the caller to specify additional arguments (all of
        which will be ignored though). The purpose of this is to allow the
        caller to unpack a dictionary whose element set is a superset of
        the required arguments by this function.
    
    @return The iteration number (i.e., the key) with which to look up the
        result in \c tbl_state
    """
    iterationCtrl = IterationControllerTableAppend(
        rel_args = tbl_args,
        rel_state = tbl_state,
        stateType = "double precision[]",
        truncAfterIteration = False,
        schema_madlib = schema_madlib, # Identifiers start here
        rel_source = tbl_source,
        col_ind_var = col_ind_var,
        col_dep_var = col_dep_var)
    
    with iterationCtrl as it:
        it.iteration = start_iter
        while True:
            # manually add the intercept term
            it.update("""
                      select
                        {schema_madlib}.__gaussian_bcd_step(
                            array_append((_src.{col_ind_var})::double precision[], 1::double precision),
                            (_src.{col_dep_var})::double precision,
                            (select _state from {rel_state}
                                where _iteration = {iteration}),
                            (_args.lambda)::double precision,
                            (_args.alpha)::double precision,
                            ((_args.dimension) + 1)::integer,
                            (_args.means)::double precision[],
                            (_args.sq)::double precision[],
                            (_args.total_rows)::integer)
                      from {rel_source} as _src, {rel_args} as _args
                      """)
         
            if it.test("""
                       {iteration} >= _args.num_iterations or
                       {schema_madlib}.__gaussian_bcd_state_diff(
                            (select _state from {rel_state}
                                where _iteration = {iteration} - 1),
                            (select _state from {rel_state}
                                where _iteration = {iteration})) < _args.tolerance
                       """):
                break

    return iterationCtrl.iteration

# ========================================================================
# ------------------------------------------------------------------------

class IterationControllerTableAppend (IterationControllerNoTableDrop):
    def __init__(self, rel_args, rel_state, stateType,
                 temporaryTables = True,
                 truncAfterIteration = False,
                 schema_madlib = "MADLIB_SCHEMA_MISSING",
                 verbose = False,
                 **kwargs):
        self.kwargs = kwargs
        self.kwargs.update(
            rel_args = rel_args,
            rel_state = rel_state,
            stateType = stateType.format(schema_madlib = schema_madlib),
            schema_madlib = schema_madlib)
        self.temporaryTables = temporaryTables
        self.truncAfterIteration = truncAfterIteration
        self.verbose = verbose
        self.inWith = False
        self.iteration = -1
        
        self.state_exists = plpy.execute("""
                                         select count(*)
                                         from information_schema.tables
                                         where table_name = '{rel_state}'
                                         """.format(**self.kwargs))[0]['count'] == 1

    ## ------------------------------------------------------------------------
            
    def update(self, newState):
        """
        Update state of calculation. In ridge case, the state is an
        array of double precision[].
        """
        newState = newState.format(iteration = self.iteration, **self.kwargs)
        self.iteration += 1
        self.runSQL("""
                    INSERT INTO {rel_state}
                    SELECT
                        {iteration},
                        ({newState})
                    """.format(iteration = self.iteration,
                               newState = newState,
                               **self.kwargs))