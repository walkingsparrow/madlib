
import plpy
from validation.cv_utils import __cv_unique_string
from utilities.control import IterationController
from convex.lasso_igd import IterationControllerNoTableDrop
from convex.ridge import __ridge_ind_var_scales
from convex.ridge import __ridge_dep_var_scale
from convex.ridge import __ridge_normalize_data
from convex.ridge import __ridge_restore_linear_coef_scales
from convex.validate_args import __is_tbl_exists
from convex.validate_args import __is_tbl_has_rows
from convex.validate_args import __is_col_exists
from convex.validate_args import __is_tbl_exists_in_schema
from convex.validate_args import __is_scalar_col_no_null
from convex.validate_args import __is_array_col_same_dimension
from convex.validate_args import __is_array_col_no_null
from convex.elastic_net_gaussian_igd import __tbl_dimension_rownum
from convex.elastic_net_gaussian_igd import __normalize_data

## ========================================================================

def __bcd_params_parser(optimizer_params):
    """
    Parse BCD parameters.
    """
    allowed_params = set(["num_iterations", "tolerance"])
    name_value = dict()
    # default values
    name_value["num_iterations"] = 100 
    name_value["tolerance"] = 0.000001
    
    for s in optimizer_params:
        items = s.split("=")
        if (len(items) != 2):
            plpy.error("Optimizer parameter list has incorrect format!")
        param_name = items[0].strip()
        param_value = items[1].strip()

        if param_name not in allowed_params:
            plpy.error("{0} is not a valid parameter name for the BCD optimizer.".format(param_name))

        if param_name == "num_iterations":
            name_value["num_iterations"] = int(param_value)

        if param_name == "tolerance":
            name_value["tolerance"] = float(param_value)

    # validate the parameters
    if name_value["num_iterations"] <= 0:
        plpy.error("Elastic Net error: num_iterations must be positive!")

    if name_value["tolerance"] <= 0:
        plpy.error("Elastic Net error: tolerance must be positive!")

    return name_value

## ========================================================================

def __bcd_create_tbl_args(**args):
    """
    create the temporary schema and argument table used in BCD iterations
    """
    if args["normalization"]:
        mean = [0] * args["dimension"]
        mean_y = 1
        sq = [1] * args["dimension"]
    else:
        tmp = plpy.execute("""
                           select array_agg(mean order by attr) as mean,
                                array_agg(sq order by attr) as sq
                           from (
                                select attr, avg(val) as mean, avg(val^2) as sq
                                from (
                                    select generate_series(1,{dimension}) as attr,
                                            unnest({col_ind_var}) as val
                                    from {tbl_source}
                                ) t
                                group by attr
                            ) s
                           """.format(**args))[0]
        mean = tmp["mean"]
        sq = tmp["sq"]
        mean_y = plpy.execute("""
                              select avg({col_dep_var}) as avg from {tbl_source}
                              """.format(**args))[0]["avg"]
        
    avg = "array["
    sqstr = "array["
    for i in range(args["dimension"]):
        avg += str(mean[i]) + ","
        sqstr += str(sq[i])
        if i != args["dimension"]-1:
            sqstr += ","
    avg += str(mean_y) + "]" # averages of independent and dependent variables, length is dimension + 1
    sqstr += "]" # averages of square of independent variables, length is dimension
    
    plpy.execute("select {schema_madlib}.create_schema_pg_temp()".format(**args))

    effective_lambda = args["lambda_value"] * args["row_num"]
    plpy.execute("""
                 drop table if exists pg_temp.{tbl_bcd_args};
                 
                 create table pg_temp.{tbl_bcd_args} (
                    dimension       integer,
                    means           double precision[],
                    sq              double precision[],
                    lambda          double precision,
                    alpha           double precision,
                    total_rows      integer,
                    num_iterations  integer,
                    tolerance       double precision);
                 """.format(**args))
    plpy.execute("""
                 insert into pg_temp.{tbl_bcd_args} values
                    ({dimension}, {avg}, {sqstr}, {effective_lambda}, {alpha},
                     {row_num}, {num_iterations}, {tolerance})
                 """.format(effective_lambda = effective_lambda, avg = avg,
                            sqstr = sqstr,
                            **args))

    return None
    
## ========================================================================

def __bcd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var,
                         tbl_result, dimension, row_num, lambda_value, alpha,
                         normalization, optimizer_params_dict):
    """
    Construct the dict used by a series of SQL queries in BCD optimizer.
    """
    args = dict(schema_madlib = schema_madlib, tbl_source = tbl_source,
                tbl_data = tbl_source, # argument name used in normalization
                col_ind_var = col_ind_var, col_dep_var = col_dep_var,
                tbl_result = tbl_result,
                lambda_value = lambda_value, alpha = alpha,
                dimension = dimension, row_num = row_num,
                normalization = normalization)
    
    # Add the optimizer parameters
    args.update(optimizer_params_dict)

    # Table names useful when normalizing the original data
    # Note: in order to be consistent with the calling convention
    # of the normalization functions, multiple elements of the dict
    # actually have the same value. This is a price that one has to pay
    # if he wants to save typing argument names by using **args as the
    # function argument.
    tbl_ind_scales = __cv_unique_string()
    tbl_dep_scale = __cv_unique_string()
    tbl_data_scaled = __cv_unique_string()
    args.update(tbl_scale = tbl_dep_scale, tbl_dep_scale = tbl_dep_scale,
                tbl_scales = tbl_ind_scales, tbl_ind_scales = tbl_ind_scales,
                tbl_data_scaled = tbl_data_scaled)

    # Table names used in BCD iterations
    args.update(tbl_bcd_state = __cv_unique_string(),
                tbl_bcd_args = __cv_unique_string())

    # Table name used as the intermediate storage before scale restores
    args.update(tbl_inter_result = __cv_unique_string())
   
    return args

## ========================================================================

def __bcd_cleanup_temp_tbls(**args):
    """
    Drop all temporary tables used by BCD optimizer,
    including tables used in the possible normalization
    and BCD iterations.
    """
    plpy.execute("""
                 drop table if exists {tbl_ind_scales};
                 drop table if exists {tbl_dep_scale};
                 drop table if exists {tbl_data_scaled};
                 drop table if exists pg_temp.{tbl_bcd_args};
                 drop table if exists pg_temp.{tbl_bcd_state};
                 """.format(**args))
    return None

## ========================================================================

def __elastic_net_gaussian_bcd_train(schema_madlib, tbl_source, col_ind_var,
                                     col_dep_var, tbl_result, lambda_value, alpha,
                                     normalization, optimizer_params, **kwargs):
    (tbl_source,
     col_ind_var,
     col_dep_var,
     tbl_result,
     lambda_value,
     alpha) = __elastic_net_gaussian_bcd_validate_args(tbl_source,
                                                       col_ind_var,
                                                       col_dep_var,
                                                       tbl_result,
                                                       lambda_value,
                                                       alpha,
                                                       normalization)
    
    return __elastic_net_gaussian_bcd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                                    col_dep_var, tbl_result, lambda_value, alpha,
                                                    normalization, optimizer_params, **kwargs)
    
## ========================================================================

def __elastic_net_gaussian_bcd_validate_args(tbl_source, col_ind_var, col_dep_var,
                                             tbl_result, lambda_value, alpha,
                                             normalization):
    if (tbl_source is None or col_ind_var is None or col_dep_var is None
        or tbl_result is None or lambda_value is None or alpha is None
        or normalization is None):
        plpy.error("Elastic Net error: You have unsupported NULL value(s) in the arguments!")
    
    if not __is_tbl_exists(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " does not exist!")

    if __is_tbl_exists_in_schema(tbl_result):
        plpy.error("Elastic Net error: Output table " + tbl_result + " already exists!")

    if not __is_tbl_has_rows(tbl_source):
        plpy.error("Elastic Net error: Data table " + tbl_source + " is empty!")

    if not __is_col_exists(tbl_source, [col_ind_var, col_dep_var]):
        plpy.error("Elastic Net error: Some column does not exist!")

    if not __is_scalar_col_no_null(tbl_source, col_dep_var):
        plpy.error("Elastic Net error: Dependent variable has Null values! Please filter out Null values before using this function!")

    if not __is_array_col_same_dimension(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have unequal lengths!")

    if not __is_array_col_no_null(tbl_source, col_ind_var):
        plpy.error("Elastic Net error: Independent variable arrays have Null values! Please filter out Null values before using this function!")

    if lambda_value < 0:
        plpy.error("Elastic Net error: The regulation parameter lambda cannot be negative!")

    if alpha < 0 or alpha > 1:
        plpy.error("Elastic Net error: The elastic net control parameter alpha must be in [0,1] !")

    return (tbl_source, col_ind_var, col_dep_var, tbl_result, lambda_value, alpha)
    
## ========================================================================
    
def __elastic_net_gaussian_bcd_train_compute(schema_madlib, tbl_source, col_ind_var,
                                             col_dep_var, tbl_result, lambda_value, alpha,
                                             normalization, optimizer_params, **kwargs):
    """
    Fit linear model with elastic net regulation using BCD optimization.

    @param tbl_source        Name of data source table
    @param col_ind_var       Name of independent variable column,
                             independent variable is an array
    @param col_dep_var       Name of dependent variable column
    @param tbl_result        Name of the table to store the results,
                             will return fitting coefficients and
                             likelihood
    @param lambda_value      The regulation parameter
    @param alpha             The elastic net parameter, [0, 1]
    @param normalization     Whether to normalize the variables
    @param optimizer_params  Parameters of the above optimizer, the format
                             is '{arg = value, ...}'::varchar[]
    """
    old_msg_level = plpy.execute("""
                                 select setting from pg_settings
                                 where name='client_min_messages'
                                 """)[0]['setting']
    plpy.execute("set client_min_messages to error")

    (dimension, row_num) = __tbl_dimension_rownum(tbl_source, col_ind_var)

    # generate a full dict to ease the following string format
    # including several temporary table names
    args = __bcd_construct_dict(schema_madlib, tbl_source, col_ind_var, col_dep_var, tbl_result,
                                dimension, row_num, lambda_value, alpha, normalization,
                                __bcd_params_parser(optimizer_params))

    # use normalized data or not
    if normalization:
        __normalize_data(**args)
        tbl_used = args["tbl_data_scaled"]
    else:
        tbl_used = tbl_source

    # create the temp table that passes parameter values to BCD optimizer
    __bcd_create_tbl_args(**args)

    # perform the actual calculation
    iteration_run = __compute_gaussian_bcd(schema_madlib, args["tbl_bcd_args"],
                                           args["tbl_bcd_state"], tbl_used,
                                           col_ind_var, col_dep_var, True)

    if normalization:
        use_temp = "temp"
    else:
        args["tbl_inter_result"] = tbl_result
        use_temp = ""
    plpy.execute("""
                 drop table if exists {tbl_inter_result};
                 create {use_temp} table {tbl_inter_result} (
                    coefficients      double precision[],
                    intercept         double precision,
                    log_likelihood    double precision,
                    normalization     boolean,
                    iteration_run        integer)
                 """.format(use_temp = use_temp, **args))

    plpy.execute("""
                 insert into {tbl_inter_result}
                    select
                        (result).coefficients[1:{dimension}],
                        (result).coefficients[{dimension}+1],
                        -(result).likelihood / {row_num},
                        False, {iteration_run}
                    from (
                        select {schema_madlib}.__gaussian_bcd_result(_state) as result
                        from {tbl_bcd_state}
                        where _iteration = {iteration_run}
                    ) t
                 """.format(iteration_run = iteration_run, **args))

    # # compute the likelihood
    # plpy.execute("""
    #              update {tbl_inter_result} set log_likelihood = llhd from (
    #                 select
    #                     -(loss + {lambda_value} * ((1 - {alpha}) * module_2 / 2. + {alpha} * module_1)) as llhd
    #                 from (
    #                     select
    #                         avg(({col_dep_var} - {schema_madlib}.elastic_net_predict('gaussian', coefficients, intercept, {col_ind_var}))^2) / 2. as loss
    #                     from
    #                         {tbl_inter_result},
    #                         {tbl_used}
    #                     ) t1,
    #                     (
    #                         select sum(coef^2) as module_2, sum(abs(coef)) as module_1
    #                         from (
    #                             select unnest(coefficients) as coef
    #                             from {tbl_inter_result}
    #                         ) s
    #                     ) t2
    #              ) u
    #              """.format(tbl_used = tbl_used, **args))
    
    if normalization:
        __ridge_restore_linear_coef_scales(tbl_coef = args["tbl_inter_result"],
                                           col_coef = "coefficients",
                                           col_others = ["log_likelihood", "normalization", "iteration_run"],
                                           tbl_origin_coef = tbl_result,
                                           **args)
        plpy.execute("update {tbl_result} set normalization = True".format(**args))

    # cleanup    
    __bcd_cleanup_temp_tbls(**args)
    if normalization:
        plpy.execute("drop table if exists {tbl_inter_result}".format(**args))
    plpy.execute("set client_min_messages to " + old_msg_level)
    return None

## ========================================================================

def __compute_gaussian_bcd(schema_madlib, tbl_args, tbl_state, tbl_source,
                           col_ind_var, col_dep_var, drop_table, **kwargs):
    """
    Driver function for elastic net with Gaussian response using BCD

    @param schema_madlib Name of the MADlib schema, properly escaped/quoted
    @param tbl_args Name of the (temporary) table containing all non-template
        arguments
    @param tbl_state Name of the (temporary) table containing the inter-iteration
        states
    @param rel_source Name of the relation containing input points
    @param col_ind_var Name of the independent variables column
    @param col_dep_var Name of the dependent variable column
    @param drop_table Boolean, whether to use IterationController (True) or
                      IterationControllerNoTableDrop (False)
    @param kwargs We allow the caller to specify additional arguments (all of
        which will be ignored though). The purpose of this is to allow the
        caller to unpack a dictionary whose element set is a superset of
        the required arguments by this function.
    
    @return The iteration number (i.e., the key) with which to look up the
        result in \c tbl_state
    """
    if drop_table:
        iterationCtrl = IterationController(
            rel_args = tbl_args,
            rel_state = tbl_state,
            stateType = "double precision[]",
            truncAfterIteration = False,
            schema_madlib = schema_madlib, # Identifiers start here
            rel_source = tbl_source,
            col_ind_var = col_ind_var,
            col_dep_var = col_dep_var)
    else:
        iterationCtrl = IterationControllerNoTableDrop(
            rel_args = tbl_args,
            rel_state = tbl_state,
            stateType = "double precision[]",
            truncAfterIteration = False,
            schema_madlib = schema_madlib, # Identifiers start here
            rel_source = tbl_source,
            col_ind_var = col_ind_var,
            col_dep_var = col_dep_var)

    with iterationCtrl as it:
        it.iteration = 0
        while True:
            # manually add the intercept term
            it.update("""
                      select
                        {schema_madlib}.__gaussian_bcd_step(
                            array_append((_src.{col_ind_var})::double precision[], 1::double precision),
                            (_src.{col_dep_var})::double precision,
                            (select _state from {rel_state}
                                where _iteration = {iteration}),
                            (_args.lambda)::double precision,
                            (_args.alpha)::double precision,
                            ((_args.dimension) + 1)::integer,
                            (_args.means)::double precision[],
                            (_args.sq)::double precision[],
                            (_args.total_rows)::integer)
                      from {rel_source} as _src, {rel_args} as _args
                      """)

            if it.test("""
                       {iteration} > _args.num_iterations or
                       {schema_madlib}.__gaussian_bcd_state_diff(
                            (select _state from {rel_state}
                                where _iteration = {iteration} - 1),
                            (select _state from {rel_state}
                                where _iteration = {iteration})) < _args.tolerance
                       """):
                break

    return iterationCtrl.iteration
    