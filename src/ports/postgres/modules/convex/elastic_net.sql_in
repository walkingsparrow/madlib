/* ----------------------------------------------------------------------- *//** 
 *
 * @file elastic_net.sql_in
 *
 * @brief SQL functions for elastic net regulation
 * @date July 2012
 *
 * @sa For a brief introduction to elastic net, see the module
 *     description \ref grp_lasso.
 *
 *//* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4') --'

/**
@addtogroup grp_elasticnet

@about

This module implements the elastic net regulation for regressions.

This method seeks to find a weight vector that, for any given training example set, minimizes:
\f[\min_{w \in R^N} L(w) + \lambda \left(\frac{(1-\alpha)}{2} \|w\|_2^2 + \alpha \|w\|_1 \right)\f]
where \f$L\f$ is the metric function that the user wants to minimize. Here \f$ \alpha \in [0,1] \f$
and \f$ lambda \geq 0 \f$. 

For Gaussian response family (or linear model), we have
\f[\min_{w \in R^N, w_{0}} \frac{1}{2}\left[\frac{1}{M} \sum_{m=1}^M (w^{t} x_m + w_{0} - y_m)^2 \right]
+ \lambda \left(\frac{(1-\alpha)}{2} \|w\|_2^2 + \alpha \|w\|_1 \right)\f]

To get better convergence, one can rescale the value of each element of x
\f[ x' \leftarrow \frac{x - \bar{x}}{\sigma_x} \f]
and
\f[y' \leftarrow y - \bar{y} \f]
and then fit 
\f[\min_{w' \in R^N} \frac{1}{2}\left[\frac{1}{M} \sum_{m=1}^M (w'^{t} x'_m - y'_m)^2 \right]
+ \lambda \left(\frac{(1-\alpha)}{2} \|w\|_2^2 + \alpha \|w\|_1 \right)\f]
At the end of the calculation, the orginal scales will be restored and an intercept term will be obtained at the same time as a by-product.

Note that fitting after scaling is not equivalent to directly fitting.

@input

The <b>training examples</b> is expected to be of the following form:
<pre>{TABLE|VIEW} <em>input_table</em> (
    ...
    <em>independentVariables</em>   DOUBLE PRECISION[],
    <em>dependentVariable</em>      DOUBLE PRECISION,
    ...
)</pre>

Null values are not expected.

@usage

- Get the fitting coefficients for a linear model:

<pre>SELECT madlib.elastic_net_train()

@examp

@literature

*/

------------------------------------------------------------------------

/**
 * @brief Interface for elastic net
 *
 * @param tbl_source        Name of data source table
 * @param col_ind_var       Name of independent variable column, independent variable is an array
 * @param col_dep_var       Name of dependent variable column
 * @param tbl_result        Name of the table to store the results, will return fitting coefficients and likelihood
 * @param lambda            The regulation parameter
 * @param alpha             The elastic net parameter, [0, 1]
 * @param normalization     Whether to normalize the variables
 * @param regress_family    Response type, 'gaussian' or 'binomial'
 * @param optimizer         The optimization algorithm, for example 'igd'
 * @param optimizer_params  Parameters of the above optimizer, the format is '{arg = value, ...}'::varchar[]
 */
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.elastic_net_train (
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_result          VARCHAR,
    lambda_value        DOUBLE PRECISION,
    alpha               DOUBLE PRECISION,
    normalization       BOOLEAN,
    regress_family      VARCHAR,
    optimizer           VARCHAR,
    optimizer_params    VARCHAR[]
) RETURNS VOID AS $$
PythonFunction(convex, elastic_net, elastic_net_train)
$$ LANGUAGE plpythonu;

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.elastic_net_train (
    tbl_source          VARCHAR,
    col_ind_var         VARCHAR,
    col_dep_var         VARCHAR,
    tbl_result          VARCHAR,
    lambda_value        DOUBLE PRECISION,
    alpha               DOUBLE PRECISION,
    normalization       BOOLEAN,
    regress_family      VARCHAR
) RETURNS VOID AS $$
BEGIN
    PERFORM MADLIB_SCHEMA.elastic_net_train($1, $2, $3, $4, $5, $6, $7, $8, 'newton', '{NULL}'::VARCHAR[]);
END;
$$ LANGUAGE plpgsql VOLATILE;

------------------------------------------------------------------------

/**
 * @brief Help function, to print out the supported families
 */
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.elastic_net_train ()
RETURNS VARCHAR AS $$
DECLARE
    str     VARCHAR;
BEGIN
    str := 'Right now, gaussian (linear) and binomial (logistic) are the supported regress_family!';
    return str;
END;
$$ LANGUAGE plpgsql STRICT;

------------------------------------------------------------------------

/**
 * @brief Help function, to print out the supported optimizer for a family
 * or print out the parameter list for an optimizer
 *
 * @param family_or_optimizer   Response type, 'gaussian' or 'binomial', or
 * optimizer type
 */
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.elastic_net_train (
    family_or_optimizer  VARCHAR
) RETURNS VARCHAR AS $$
PythonFunction(convex, elastic_net, elastic_net_help)
$$ LANGUAGE plpythonu;

------------------------------------------------------------------------
-- Compute the solution for just one step ------------------------------
------------------------------------------------------------------------

CREATE TYPE MADLIB_SCHEMA.__elastic_net_result AS (
    coefficients    DOUBLE PRECISION[],
    likelihood      DOUBLE PRECISION
);

------------------------------------------------------------------------

CREATE FUNCTION MADLIB_SCHEMA.__gaussian_igd_transition (
    state               DOUBLE PRECISION[],
    ind_var             DOUBLE PRECISION[],
    dep_var             DOUBLE PRECISION,
    pre_state           DOUBLE PRECISION[],
    lambda              DOUBLE PRECISION,
    alpha               DOUBLE PRECISION,
    dimension           INTEGER,
    stepsize            DOUBLE PRECISION,
    total_rows          INTEGER
) RETURNS DOUBLE PRECISION[]
AS 'MODULE_PATHNAME', 'gaussian_igd_transition'
LANGUAGE C IMMUTABLE;

--

CREATE FUNCTION MADLIB_SCHEMA.__gaussian_igd_merge (
    state1              DOUBLE PRECISION[],
    state2              DOUBLE PRECISION[]
) RETURNS DOUBLE PRECISION[] AS
'MODULE_PATHNAME', 'gaussian_igd_merge'
LANGUAGE C IMMUTABLE STRICT;

--

CREATE FUNCTION MADLIB_SCHEMA.__gaussian_igd_final (
    state               DOUBLE PRECISION[]
) RETURNS DOUBLE PRECISION[] AS
'MODULE_PATHNAME', 'gaussian_igd_final'
LANGUAGE C IMMUTABLE STRICT;

/**
 * @internal
 * @brief Perform one iteration step of IGD for linear models
 */
CREATE AGGREGATE MADLIB_SCHEMA.__gaussian_igd_step(
    /* ind_var */           DOUBLE PRECISION[],
    /* dep_var */           DOUBLE PRECISION,
    /* pre_state */         DOUBLE PRECISION[],
    /* lambda  */           DOUBLE PRECISION,
    /* alpha */             DOUBLE PRECISION,
    /* dimension */         INTEGER,
    /* stepsize */          DOUBLE PRECISION,
    /* total_rows */        INTEGER
) (
    SType = DOUBLE PRECISION[],
    SFunc = MADLIB_SCHEMA.__gaussian_igd_transition,
    m4_ifdef(`GREENPLUM', `prefunc = MADLIB_SCHEMA.__gaussian_igd_merge,')
    FinalFunc = MADLIB_SCHEMA.__gaussian_igd_final,
    InitCond = '{0,0,0,0,0,0,0,0}'
);

--

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__gaussian_igd_state_diff (
    state1          DOUBLE PRECISION[],
    state2          DOUBLE PRECISION[]
) RETURNS DOUBLE PRECISION AS
'MODULE_PATHNAME', 'internal_gaussian_igd_state_diff'
LANGUAGE C IMMUTABLE STRICT;

--

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.__gaussian_igd_result (
    in_state        DOUBLE PRECISION[]
) RETURNS MADLIB_SCHEMA.__elastic_net_result AS
'MODULE_PATHNAME', 'internal_gaussian_igd_result'
LANGUAGE C IMMUTABLE STRICT;

--
/**
 * @brief Prediction use learned coefficients for a given example
 *
 * @param coefficients  Weight vector (hyperplane, classifier)
 * @param intercept     Linear fitting intercept
 * @param ind_var       Features (independent variables)
 */
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.gaussian_igd_predict (
    coefficients    DOUBLE PRECISION[],
    intercept       DOUBLE PRECISION,
    ind_var         DOUBLE PRECISION[]
) RETURNS DOUBLE PRECISION AS
'MODULE_PATHNAME', 'gaussian_igd_predict'
LANGUAGE C IMMUTABLE STRICT;
