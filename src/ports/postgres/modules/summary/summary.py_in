"""
@file summary.py_in 

@brief Summary function for descriptive statistics

@namespace summary
"""
import plpy
from time import time

class Summarizer:
    def __init__(self, schema_madlib, tablename, outputtable, grouping_cols, distinctify, ntileify):
        self.schema_madlib = schema_madlib
        self.distinctify = distinctify
        self.ntileify = ntileify
        self.tablename = tablename
        self.outputtable = outputtable
        self.grouping_cols = grouping_cols
        self.tableoid = None
        self.columns = None

    def get_columns(self):
        try:
            self.tableoid = plpy.execute("""
              SELECT '{tablename}'::regclass::oid
              """.format(tablename=self.tablename))[0]['oid']
        except:
            plpy.error("ERROR: table '{tablename}' does not exist".format(tablename=self.tablename))

        self.columns = plpy.execute("""
              SELECT attname, typname, attnum 
              FROM pg_attribute a join pg_type t on (a.atttypid=t.oid) 
              WHERE attrelid = {tableoid}::regclass and attnum > 0 and not attisdropped
              ORDER BY attnum
              """.format(tableoid=self.tableoid))

    def check_grouping_cols(self):
        col_names = []
        for col in self.columns:
            col_names.append(col['attname'])

        non_exist_cols = []
        for col in self.grouping_cols:
            if col is not None and col not in col_names:
                non_exist_cols.append(col)
        if len(non_exist_cols) > 0:
            plpy.error("ERROR: column(s) %s not exist" % (str(non_exist_cols)[1:-1]))

    def build_subquery(self, groupVar):
        d = {'tablename': self.tablename}
        # Exclude the grouping_cols variable from the list of columns to report statistics on
        cols = filter(lambda x: x['attname'] != groupVar, self.columns)
    
        if groupVar is not None:
            d['groupVal']  = "{schema_madlib}.__to_char(%s)" % groupVar
            d['groupVar']  = "'%s'" % groupVar
            d['groupExpr'] = "\n       GROUP BY %s" % groupVar
        else:
            d['groupVal'] = "NULL"
            d['groupVar']  = "NULL"
            d['groupExpr'] = ""
    
        d['column_names'] = ','.join(["'%s'" % c['attname'] for c in cols])
        d['column_types'] = ','.join(["'%s'" % c['typname'] for c in cols])
        d['column_number'] = ','.join([str(c['attnum']) for c in cols])
        if self.distinctify is 'Estimated':
            d['distinct_columns'] = ','.join(["{schema_madlib}.fmsketch_dcount(%s)" % c['attname'] for c in cols])
        elif self.distinctify is 'Exact':
            d['distinct_columns'] = ','.join(["count(distinct %s)" % c['attname'] for c in cols])
        else:
            d['distinct_columns'] = ','.join(["NULL" for c in cols])
        d['missing_columns'] = ','.join(["count(%s) filter (where %s is null)" % (c['attname'],c['attname']) for c in cols])
    
        def numeric_type(operator, c):
            if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                return '%s(%s)' % (operator, c['attname'])
            return "NULL"
    
        def minmax_type(minmax, c):
            if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                return '%s(%s)' % (minmax, c['attname'])
            if c['typname'] in ('varchar','bpchar','text'):
                return "%s(length(%s))" % (minmax, c['attname'])
            return "NULL"
    
        def quant_type(ntile, c):
            if self.ntileify is 'Exact':
                if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                    return "percentile_cont(%s) WITHIN GROUP (ORDER BY %s)" % (ntile, c['attname'])
            if self.ntileify is 'Estimated':
                return "NULL"  # NOT YET IMPLEMENTED
            return "NULL"
    
        d['mean_columns'] = ','.join([numeric_type('avg',c) for c in cols])
        d['var_columns'] = ','.join([numeric_type('variance',c) for c in cols])
        d['min_columns'] = ','.join([minmax_type('min',c) for c in cols])
        d['q1_columns'] = ','.join([quant_type('0.25',c) for c in cols])
        d['q2_columns'] = ','.join([quant_type('0.50',c) for c in cols])
        d['q3_columns'] = ','.join([quant_type('0.75',c) for c in cols])
        d['max_columns'] = ','.join([minmax_type('max',c) for c in cols])
    
        return """
           SELECT 
             {groupVar}::text as group_by,
             {groupVal}::text as group_by_value, 
             array[{column_names}]::text[] as target_column,
             array[{column_types}]::text[] as datatype,
             array[{column_number}]::integer[] as colnum,
             count(*)::bigint as rowcount,
             array[{mean_columns}]::float8[] as mean,
             array[{var_columns}]::float8[] as variance,
             array[{distinct_columns}]::bigint[] as distinct_values,
             array[{missing_columns}]::bigint[] as missing_values,
             array[{min_columns}]::float8[] as min,
             array[{q1_columns}]::float8[] as first_quartile,
             array[{q2_columns}]::float8[] as median,
             array[{q3_columns}]::float8[] as third_quartile,
             array[{max_columns}]::float8[] as max
           FROM {tablename}{groupExpr}
         """.format(**d).format(schema_madlib = self.schema_madlib)

    def build_query(self):
        subquery = """  UNION ALL""".join([self.build_subquery(g) for g in self.grouping_cols])
        plpy.execute("DROP TABLE IF EXISTS {outtablename};".format(outtablename =  self.outputtable))
        query = """
          CREATE TABLE {outtablename} AS
          SELECT
            group_by,
            group_by_value,
            target_column,
            datatype,
            colnum,
            rowcount,
            distinct_values,
            missing_values,
            distinct_values::float8 / rowcount as fraction_distinct_values,
            missing_values::float8 / rowcount as fraction_missing_values,
            mean,
            variance,
            min,
            first_quartile,
            median,
            third_quartile,
            max
          FROM (
            SELECT 
              group_by,
              group_by_value,
              unnest(target_column) AS target_column,
              unnest(datatype) AS datatype,
              unnest(colnum) AS colnum,
              rowcount,
              unnest(distinct_values) as distinct_values,
              unnest(missing_values) as missing_values,
              unnest(mean) as mean,
              unnest(variance) as variance,
              unnest(min) as min,
              unnest(first_quartile) as first_quartile,
              unnest(median) as median,
              unnest(third_quartile) as third_quartile,
              unnest(max) as max
            FROM ({subquery}) q1
          ) q2
          m4_ifdef(`__GREENPLUM__', `DISTRIBUTED BY (group_by)')
        """.format(subquery=subquery, outtablename = self.outputtable)
        return query

    def run(self):
        self.get_columns()
        self.check_grouping_cols()
        results = plpy.execute(self.build_query())
 
def summary(schema_madlib, tablename, outputtable, grouping_cols, distinctify, ntileify):
    if distinctify not in ['Estimated', 'Exact', 'None']:
        plpy.error("Invalid parameter: distinctify must be in ['Estimated', 'Exact', 'None']")

    if ntileify not in ['Estimated', 'Exact', 'None']:
        plpy.error("Invalid paramter: ntileify must be in ['Estimated', 'Exact', 'None']")
     
    if outputtable == "":
        plpy.error("Invalid parameter: outputtable should be a non-empty string")

    if grouping_cols.strip() == '':
        grouping_cols = [None]
    else:
        grouping_cols = grouping_cols.replace(' ', '').split(',')
        grouping_cols.append(None)

    start = time()
    summarizer = Summarizer(schema_madlib, tablename, outputtable, grouping_cols, distinctify, ntileify)
    summarizer.run()
    end = time()

    return "output written to table: %s, duration: %s" % (outputtable, end - start)
