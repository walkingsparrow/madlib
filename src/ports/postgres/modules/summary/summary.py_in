"""
@file summary.py_in 

@brief Summary function for descriptive statistics

@namespace summary
"""
import plpy
from time import time

class Summarizer:
    def __init__(self, schema_madlib, tablename, outputtable, target_cols , 
                 grouping_cols, distinctify, ntileify, ntile_array):
        self._schema_madlib = schema_madlib
        self._tablename = tablename
        self._outputtable = outputtable
        self._grouping_cols = grouping_cols
        self._target_cols = target_cols
        self._distinctify = distinctify
        self._ntileify = ntileify
        self._ntile_array = ntile_array
        self._tableoid = None
        self._columns = None
        self._column_names = None

    def _get_columns(self):
        try:
            self._tableoid = plpy.execute("""
              SELECT '{tablename}'::regclass::oid
              """.format(tablename=self._tablename))[0]['oid']
        except:
            plpy.error("ERROR: table '{tablename}' \
                            does not exist".format(tablename=self._tablename))

        self._columns = plpy.execute("""
              SELECT attname, typname, attnum 
              FROM pg_attribute a join pg_type t on (a.atttypid=t.oid) 
              WHERE attrelid = {tableoid}::regclass and attnum > 0 and not attisdropped
              ORDER BY attnum
              """.format(tableoid=self._tableoid))

        self._column_names = []
        for col in self._columns:
            self._column_names.append(col['attname'])

    def _check_grouping_cols(self):
        non_exist_cols = []
        for col in self._grouping_cols:
            if col is not None and col not in self._column_names:
                non_exist_cols.append(col)
        if len(non_exist_cols) > 0:
            plpy.error("ERROR: column(s) %s do not exist" % (str(non_exist_cols)[1:-1]))

    def _check_target_cols(self):
        non_exist_cols = []
        if self._target_cols is None:
            return
        for col in self._target_cols:
            if col not in self._column_names:
                non_exist_cols.append(col)
        if len(non_exist_cols) > 0:
            plpy.error("ERROR: column(s) %s do not exist" % (str(non_exist_cols)[1:-1]))

    def _build_subquery(self, groupVar):
        d = {'tablename': self.tablename}
        # Exclude the grouping_cols variable from the list of columns to report statistics on
        cols = filter(lambda x: x['attname'] != groupVar, self._columns)
    
        if groupVar is not None:
            d['groupVal']  = "{schema_madlib}.__to_char(%s)" % groupVar
            d['groupVar']  = "'%s'" % groupVar
            d['groupExpr'] = "\n       GROUP BY %s" % groupVar
        else:
            d['groupVal'] = "NULL"
            d['groupVar']  = "NULL"
            d['groupExpr'] = ""
    
        d['column_names'] = ','.join(["'%s'" % c['attname'] for c in cols])
        d['column_types'] = ','.join(["'%s'" % c['typname'] for c in cols])
        d['column_number'] = ','.join([str(c['attnum']) for c in cols])
        if self._distinctify is 'Estimated':
            d['distinct_columns'] = ','.join(["{schema_madlib}.fmsketch_dcount(%s)" % c['attname'] for c in cols])
        elif self._distinctify is 'Exact':
            d['distinct_columns'] = ','.join(["count(distinct %s)" % c['attname'] for c in cols])
        else:
            d['distinct_columns'] = ','.join(["NULL" for c in cols])
        d['missing_columns'] = ','.join(["count(%s) filter (where %s is null)" % (c['attname'],c['attname']) for c in cols])
    
        def numeric_type(operator, c):
            if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                return '%s(%s)' % (operator, c['attname'])
            return "NULL"
    
        def minmax_type(minmax, c):
            if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                return '%s(%s)' % (minmax, c['attname'])
            if c['typname'] in ('varchar','bpchar','text'):
                return "%s(length(%s))" % (minmax, c['attname'])
            return "NULL"
    
        def quant_type(ntile, c):
            if self._ntileify is 'Exact':
                if c['typname'] in ('int2','int4','int8','float4','float8','numeric'):
                    return "percentile_cont(%s) WITHIN GROUP (ORDER BY %s)" % (ntile, c['attname'])
            if self._ntileify is 'Estimated':
                return "NULL"  # NOT YET IMPLEMENTED
            return "NULL"
    
        d['mean_columns'] = ','.join([numeric_type('avg',c) for c in cols])
        d['var_columns'] = ','.join([numeric_type('variance',c) for c in cols])
        d['min_columns'] = ','.join([minmax_type('min',c) for c in cols])
        d['q1_columns'] = ','.join([quant_type('0.25',c) for c in cols])
        d['q2_columns'] = ','.join([quant_type('0.50',c) for c in cols])
        d['q3_columns'] = ','.join([quant_type('0.75',c) for c in cols])
        d['max_columns'] = ','.join([minmax_type('max',c) for c in cols])
        
        d['ntile_columns'] = "array_to_string(array[NULL], ',')"
        if self._ntile_array is not None:
            d['ntile_columns'] = ",".join([
                "array_to_string(array[" +
                ",".join([quant_type(ntile, c) for ntile in self._ntile_array])
                + "], ',')" for c in cols])

        return """
                SELECT 
                    {groupVar}::text as group_by,
                    {groupVal}::text as group_by_value, 
                    array[{column_names}]::text[] as target_column,
                    array[{column_types}]::text[] as datatype,
                    array[{column_number}]::integer[] as colnum,
                    count(*)::bigint as rowcount,
                    array[{mean_columns}]::float8[] as mean,
                    array[{var_columns}]::float8[] as variance,
                    array[{distinct_columns}]::bigint[] as distinct_values,
                    array[{missing_columns}]::bigint[] as missing_values,
                    array[{min_columns}]::float8[] as min,
                    array[{q1_columns}]::float8[] as first_quartile,
                    array[{q2_columns}]::float8[] as median,
                    array[{q3_columns}]::float8[] as third_quartile,
                    array[{ntile_columns}]::text[] as ntiles,
                    array[{max_columns}]::float8[] as max
                FROM {tablename}{groupExpr}
         """.format(**d).format(schema_madlib = self.schema_madlib)

    def build_query(self):
        subquery = """  UNION ALL""".join([self.build_subquery(g) for g in self._grouping_cols])
        plpy.execute("DROP TABLE IF EXISTS {outtablename};".format(outtablename =  self._outputtable))
        query = """
            CREATE TABLE {outtablename} AS
            SELECT
                    group_by,
                    group_by_value,
                    target_column,
                    datatype,
                    colnum,
                    rowcount,
                    distinct_values,
                    missing_values,
                    distinct_values::float8 / rowcount as fraction_distinct_values,
                    missing_values::float8 / rowcount as fraction_missing_values,
                    mean,
                    variance,
                    min,
                    first_quartile,
                    median,
                    third_quartile,
                    ntiles::float8[],
                    max
            FROM
            (
                SELECT
                    group_by,
                    group_by_value,
                    target_column,
                    datatype,
                    colnum,
                    rowcount,
                    distinct_values,
                    missing_values,
                    distinct_values::float8 / rowcount as fraction_distinct_values,
                    missing_values::float8 / rowcount as fraction_missing_values,
                    mean,
                    variance,
                    min,
                    first_quartile,
                    median,
                    third_quartile,
                    ntiles,
                    max
                FROM 
                (
                    SELECT 
                        group_by,
                        group_by_value,
                        unnest(target_column) AS target_column,
                        unnest(datatype) AS datatype,
                        unnest(colnum) AS colnum,
                        rowcount,
                        unnest(distinct_values) as distinct_values,
                        unnest(missing_values) as missing_values,
                        unnest(mean) as mean,
                        unnest(variance) as variance,
                        unnest(min) as min,
                        unnest(first_quartile) as first_quartile,
                        unnest(median) as median,
                        unnest(third_quartile) as third_quartile,
                        string_to_array(unnest(ntiles), ',') as ntiles,
                        unnest(max) as max
                    FROM ({subquery}) q1
                ) q2
            ) q3
            m4_ifdef(`__GREENPLUM__', `DISTRIBUTED BY (group_by)')
        """.format(subquery=subquery, outtablename = self._outputtable)
        return query

    def _adjust_cols(self):
        tcols = self._target_cols
        if tcols is None:
            tcols = self._column_names

        # if #tcols == 1, then it should not appear in the grouping_cols
        if len(tcols) == 1 and tcols[0] in self._grouping_cols:
            self._grouping_cols.remove(tcols[0])

        if self._target_cols is not None:
            self._columns = filter(
                lambda r: r['attname'] in self._target_cols, self._columns)

    def run(self):
        self._get_columns()
        self._check_target_cols()
        self._check_grouping_cols()
        self._adjust_cols()
        results = plpy.execute(self._build_query())
 
def summary(
    schema_madlib, tablename, outputtable, target_cols, grouping_cols,
    to_compute_distinct, to_compute_quartiles, ntile_array):

    # distinctify can be one of the following values: 'Estimated', 'Exact', and
    # 'None'.
    distinctify = 'Estimated'

    # ntileify can take one of the following values: 'Estimated', 'Exact', and
    # 'None', but currently "Estimated" is not supported.
    ntileify = 'Exact'
     
    if outputtable is None or outputtable.strip() == '':
        plpy.error("Invalid parameter: outputtable should be a non-empty string")

    if target_cols is None or target_cols.strip() == '':
        target_cols = None
    else:
        target_cols = target_cols.replace(' ', '').split(',')

    if grouping_cols is None or grouping_cols.strip() == '':
        grouping_cols = [None]
    else:
        grouping_cols = grouping_cols.replace(' ', '').split(',')
        grouping_cols.append(None)

    if not to_compute_distinct:
        distinctify = 'None'
    if not to_compute_quartiles:
        ntileify = 'None'
        
    if ntile_array is not None:
        for ntile in ntile_array:
            if ntile < 0 or ntile > 1.0:
                plpy.error(
                    """Invalid parameter: values in ntile_array should be in the
                    range of [0.0, 1.0]""")

    start = time()
    summarizer = Summarizer(
        schema_madlib, tablename, outputtable, target_cols, grouping_cols,
        distinctify, ntileify, ntile_array)
    summarizer.run()
    end = time()

    return "Output written to table: {0} in {1} ms".format(outputtable, 
                                                                end - start)
